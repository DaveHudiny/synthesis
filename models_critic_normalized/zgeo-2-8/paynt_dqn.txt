2024-08-29 16:58:32,996 - cli.py - This is Paynt version 0.1.0.
2024-08-29 16:58:32,996 - sketch.py - loading sketch from models_critic_2/zgeo-2-8/sketch.templ ...
2024-08-29 16:58:32,996 - sketch.py - assuming sketch in PRISM format...
2024-08-29 16:58:32,999 - prism_parser.py - PRISM model type: POMDP
2024-08-29 16:58:32,999 - prism_parser.py - loading properties from models_critic_2/zgeo-2-8/sketch.props ...
2024-08-29 16:58:33,000 - prism_parser.py - found the following specification: optimality: Pmax=? ["notbad" U "goal"] 
2024-08-29 16:58:33,342 - sketch.py - sketch parsing OK
2024-08-29 16:58:33,398 - sketch.py - constructed explicit quotient having 45391 states and 166762 actions
2024-08-29 16:58:33,398 - property.py - converting until formula to eventually...
2024-08-29 16:58:33,398 - sketch.py - found the following specification optimality: Pmax=? [F "goal"] 
2024-08-29 16:58:33,446 - pomdp.py - constructed POMDP having 7 observations.
2024-08-29 16:58:33,458 - pomdp.py - unfolding 1-FSC template into POMDP...
2024-08-29 16:58:33,515 - pomdp.py - constructed quotient MDP having 45391 states and 166762 actions.
2024-08-29 16:58:34,510 - tpu_cluster_resolver.py - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-08-29 16:58:34,802 - __init__.py - Creating converter from 7 to 5
2024-08-29 16:58:34,802 - __init__.py - Creating converter from 5 to 7
2024-08-29 16:58:34,802 - __init__.py - Creating converter from 7 to 5
2024-08-29 16:58:34,802 - __init__.py - Creating converter from 5 to 7
2024-08-29 16:58:36,169 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-08-29 16:58:36,169 - synthesizer_pomdp.py - Storm settings: iterative - (400, 30, 5), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False
2024-08-29 16:58:36,206 - synthesizer_pomdp.py - Timeout for PAYNT started
> progress 0.0%, elapsed 3 s, estimated 3528207 s (40 days), iters = {MDP: 3}
-----------PAYNT-----------                     
Value = 0.5319965092335829 | Time elapsed = 3.6s | FSC size = 14

> progress 25.0%, elapsed 7 s, estimated 31 s, iters = {MDP: 8}, opt = 0.532
-----------PAYNT-----------                     
Value = 0.5694957103184766 | Time elapsed = 8.9s | FSC size = 14

> progress 75.0%, elapsed 10 s, estimated 14 s, iters = {MDP: 18}, opt = 0.569
2024-08-29 16:58:47,244 - synthesizer.py - double-checking specification satisfiability:  : 0.5694957103184766
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 11.04 s
number of holes: 2, family size: 16, quotient: 45391 states / 166762 actions
explored: 100 %
MDP stats: avg MDP size: 21859, iterations: 21

optimum: 0.569496
--------------------
2024-08-29 16:59:08,273 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-08-29 16:59:08,280 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-08-29 16:59:08,963 - pomdp.py - constructed quotient MDP having 90782 states and 667048 actions.
2024-08-29 16:59:09,814 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 16:59:09,915 - storm_pomdp_control.py - Interactive Storm started
2024-08-29 16:59:09,915 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-08-29 16:59:16,922 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6125160295208801 | Time elapsed = 52.2s | FSC size = 4579


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6125160295208801
controller size: 4579

------------------------------------

2024-08-29 16:59:29,151 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-08-29 16:59:29,839 - synthesizer_ar_storm.py - Resuming synthesis
2024-08-29 16:59:29,839 - synthesizer_ar_storm.py - Additional memory needed
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 0.0 s
number of holes: 18, family size: 1e6, quotient: 90782 states / 667048 actions
explored: 0 %

optimum: 0.569496
--------------------
2024-08-29 16:59:29,839 - synthesizer_pomdp.py - Assignment is None
2024-08-29 16:59:29,839 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-08-29 16:59:29,875 - pomdp.py - unfolding 4-FSC template into POMDP...
2024-08-29 16:59:31,548 - pomdp.py - constructed quotient MDP having 166762 states and 2597857 actions.
2024-08-29 16:59:34,685 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
> progress 0.0%, elapsed 4 s, estimated 4817102 s (55 days), iters = {MDP: 2}, opt = 0.569
> progress 0.0%, elapsed 10 s, estimated 10716372 s (124 days), iters = {MDP: 3}, opt = 0.569
> progress 0.0%, elapsed 16 s, estimated 16833169 s (194 days), iters = {MDP: 4}, opt = 0.569
> progress 0.0%, elapsed 22 s, estimated 22952814 s (265 days), iters = {MDP: 5}, opt = 0.569
2024-08-29 17:00:08,290 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 17:00:08,303 - storm_pomdp_control.py - Interactive Storm resumed
2024-08-29 17:00:08,303 - storm_pomdp_control.py - Updating FSC values in Storm
2024-08-29 17:00:14,311 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6126840087366113 | Time elapsed = 119.6s | FSC size = 4787


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6126840087366113
controller size: 4787

------------------------------------

2024-08-29 17:00:36,589 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-08-29 17:00:37,324 - synthesizer_ar_storm.py - Resuming synthesis
2024-08-29 17:00:37,324 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-08-29 17:00:37,324 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:00:37,324 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:00:37,325 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:00:37,325 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 15, Subfamilies - 0
> progress 0.39%, elapsed 34 s, estimated 8709 s (2 hours), iters = {MDP: 7}, opt = 0.569
> progress 0.39%, elapsed 41 s, estimated 10577 s (2 hours), iters = {MDP: 8}, opt = 0.569
> progress 0.39%, elapsed 47 s, estimated 12228 s (3 hours), iters = {MDP: 9}, opt = 0.569
> progress 0.39%, elapsed 53 s, estimated 13809 s (3 hours), iters = {MDP: 10}, opt = 0.569
> progress 0.39%, elapsed 59 s, estimated 15354 s (4 hours), iters = {MDP: 11}, opt = 0.569
2024-08-29 17:01:09,072 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 17:01:09,119 - storm_pomdp_control.py - Interactive Storm resumed
2024-08-29 17:01:09,119 - storm_pomdp_control.py - Updating FSC values in Storm
2024-08-29 17:01:15,128 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6151938138901643 | Time elapsed = 196.4s | FSC size = 5780


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6151938138901643
controller size: 5780

------------------------------------

2024-08-29 17:01:53,439 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-08-29 17:01:54,123 - synthesizer_ar_storm.py - Resuming synthesis
2024-08-29 17:01:54,123 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,123 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:01:54,124 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:01:54,125 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:01:54,125 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 29, Subfamilies - 0
> progress 0.39%, elapsed 65 s, estimated 16802 s (4 hours), iters = {MDP: 12}, opt = 0.569
> progress 0.39%, elapsed 71 s, estimated 18276 s (5 hours), iters = {MDP: 13}, opt = 0.569
> progress 0.39%, elapsed 75 s, estimated 19358 s (5 hours), iters = {MDP: 14}, opt = 0.569
> progress 0.39%, elapsed 80 s, estimated 20531 s (5 hours), iters = {MDP: 15}, opt = 0.569
> progress 0.39%, elapsed 88 s, estimated 22529 s (6 hours), iters = {MDP: 16}, opt = 0.569
2024-08-29 17:02:23,535 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 17:02:23,574 - storm_pomdp_control.py - Interactive Storm resumed
2024-08-29 17:02:23,575 - storm_pomdp_control.py - Updating FSC values in Storm
2024-08-29 17:02:29,583 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6167333800017228 | Time elapsed = 263.8s | FSC size = 10736


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6167333800017228
controller size: 10736

------------------------------------

2024-08-29 17:03:01,452 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-08-29 17:03:01,666 - synthesizer_ar_storm.py - Resuming synthesis
2024-08-29 17:03:01,666 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-08-29 17:03:01,666 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:03:01,666 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:03:01,666 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:03:01,666 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,666 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:03:01,667 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:03:01,668 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 256 to 256
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 256 to 256
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:03:01,669 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:03:01,669 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 43, Subfamilies - 0
> progress 0.39%, elapsed 94 s, estimated 24293 s (6 hours), iters = {MDP: 18}, opt = 0.569
> progress 0.39%, elapsed 98 s, estimated 25266 s (7 hours), iters = {MDP: 24}, opt = 0.569
> progress 0.39%, elapsed 101 s, estimated 26104 s (7 hours), iters = {MDP: 29}, opt = 0.569
> progress 0.39%, elapsed 105 s, estimated 27096 s (7 hours), iters = {MDP: 33}, opt = 0.569
> progress 0.39%, elapsed 122 s, estimated 31424 s (8 hours), iters = {MDP: 40}, opt = 0.569
2024-08-29 17:03:36,579 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 17:03:36,601 - storm_pomdp_control.py - Interactive Storm resumed
2024-08-29 17:03:36,601 - storm_pomdp_control.py - Updating FSC values in Storm
2024-08-29 17:03:42,610 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6167333800017228 | Time elapsed = 338.9s | FSC size = 10739


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6167333800017228
controller size: 10739

------------------------------------

2024-08-29 17:04:15,860 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-08-29 17:04:16,626 - synthesizer_ar_storm.py - Resuming synthesis
2024-08-29 17:04:16,626 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,627 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e6 to 1e6
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 262144 to 262144
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:04:16,628 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 65536 to 65536
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16384 to 16384
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4096 to 4096
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1024 to 1024
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:04:16,629 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 64 to 64
2024-08-29 17:04:16,630 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16 to 16
2024-08-29 17:04:16,630 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16 to 16
2024-08-29 17:04:16,630 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16 to 16
2024-08-29 17:04:16,630 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 16 to 16
2024-08-29 17:04:16,630 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 44, Subfamilies - 0
> progress 0.39%, elapsed 129 s, estimated 33209 s (9 hours), iters = {MDP: 41}, opt = 0.569
> progress 0.39%, elapsed 140 s, estimated 36093 s (10 hours), iters = {MDP: 46}, opt = 0.569
> progress 0.39%, elapsed 148 s, estimated 38054 s (10 hours), iters = {MDP: 50}, opt = 0.569
> progress 0.39%, elapsed 157 s, estimated 40243 s (11 hours), iters = {MDP: 51}, opt = 0.569
2024-08-29 17:04:46,398 - synthesizer_ar_storm.py - Pausing synthesis
2024-08-29 17:04:46,498 - storm_pomdp_control.py - Interactive Storm resumed
2024-08-29 17:04:46,499 - storm_pomdp_control.py - Updating FSC values in Storm
2024-08-29 17:04:52,508 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.6167333800017228 | Time elapsed = 409.8s | FSC size = 10739


------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6167333800017228
controller size: 10739

------------------------------------

2024-08-29 17:05:27,444 - synthesizer_ar_storm.py - Terminating controller synthesis
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 159.44 s
number of holes: 18, family size: 1e10, quotient: 166762 states / 2597857 actions
explored: 0 %
MDP stats: avg MDP size: 100784, iterations: 54

optimum: 0.569496
--------------------
2024-08-29 17:05:27,444 - synthesizer_pomdp.py - Assignment is None
2024-08-29 17:05:27,459 - storm_pomdp_control.py - Storm POMDP analysis completed
2024-08-29 17:05:28,851 - synthesizer_rl.py - RL Environment initialized
2024-08-29 17:05:29,252 - recurrent_dqn_agent.py - Creating agent
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 rnn_wrapper (RNNWrapper)    multiple                  41600     
                                                                 
 dense (Dense)               multiple                  10100     
                                                                 
 dense_1 (Dense)             multiple                  10100     
                                                                 
 sequential (Sequential)     multiple                  606       
                                                                 
=================================================================
Total params: 62406 (243.77 KB)
Trainable params: 62406 (243.77 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
None
2024-08-29 17:05:29,413 - recurrent_dqn_agent.py - Agent initialized
2024-08-29 17:05:29,443 - recurrent_dqn_agent.py - Replay buffer initialized
2024-08-29 17:05:29,451 - recurrent_dqn_agent.py - Collector driver initialized
2024-08-29 17:05:29,451 - synthesizer_pomdp.py - Training agent with FSC.
2024-08-29 17:05:29,508 - synthesizer_rl.py - Agent not loaded, training from scratch.
2024-08-29 17:05:30,228 - father_agent.py - Training agent
2024-08-29 17:05:33,624 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:33,637 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:33,677 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:34,393 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:34,427 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:36,560 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:37,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:38,697 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:42,919 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:42,953 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:42,961 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:43,676 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:45,093 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:46,498 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:47,213 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:50,013 - father_agent.py - Random Average Return = (-246.0, -187.5, 0.0)
2024-08-29 17:05:50,206 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:50,229 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:50,267 - environment_wrapper.py - Ended, but not in a goal state: []
()
()
2024-08-29 17:05:50,870 - environment_wrapper.py - Goal reached!
2024-08-29 17:05:51,944 - father_agent.py - Step: 0, Training loss: 272.6100769042969
2024-08-29 17:05:55,795 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:05:57,210 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:00,744 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:00,755 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:01,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:03,616 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:04,342 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:06,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:06,501 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:08,641 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:10,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:10,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:10,173 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:11,619 - father_agent.py - Average Return = -264.5
2024-08-29 17:06:11,620 - father_agent.py - Average Virtual Goal Value = -162.5
2024-08-29 17:06:11,620 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:06:12,849 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:12,943 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:13,040 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:14,286 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:14,384 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:14,465 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:14,513 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:14,540 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:14,551 - father_agent.py - Step: 10, Training loss: 101.69467163085938
2024-08-29 17:06:14,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:15,835 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:15,930 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:16,073 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:16,141 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:16,209 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:16,350 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:16,425 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:17,638 - father_agent.py - Step: 20, Training loss: 85.76741027832031
2024-08-29 17:06:17,774 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:17,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:17,884 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:17,906 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:17,988 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:18,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,246 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,314 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,367 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,378 - father_agent.py - Step: 30, Training loss: 131.3707275390625
2024-08-29 17:06:19,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,475 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,525 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,591 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,619 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,743 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:19,823 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,889 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,948 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:19,958 - father_agent.py - Step: 40, Training loss: 131.16864013671875
2024-08-29 17:06:19,993 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:20,015 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:20,107 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,385 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:21,409 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:21,537 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,618 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:21,710 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,720 - father_agent.py - Step: 50, Training loss: 145.72482299804688
2024-08-29 17:06:21,755 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,795 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:21,852 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:21,984 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:23,285 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,335 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,399 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:23,409 - father_agent.py - Step: 60, Training loss: 113.64228057861328
2024-08-29 17:06:23,461 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,548 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,584 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:23,667 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,727 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:23,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:23,841 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:25,085 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:25,259 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:25,269 - father_agent.py - Step: 70, Training loss: 159.65447998046875
2024-08-29 17:06:25,415 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:25,511 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:25,592 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:25,729 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:25,818 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:25,859 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:25,892 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:25,940 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,007 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:26,061 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,071 - father_agent.py - Step: 80, Training loss: 96.3947525024414
2024-08-29 17:06:26,094 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:26,283 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,346 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:26,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:26,507 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,618 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,670 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,709 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:26,781 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,844 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,854 - father_agent.py - Step: 90, Training loss: 236.04380798339844
2024-08-29 17:06:26,922 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:26,991 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:27,077 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:27,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:27,170 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:27,228 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:28,528 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:28,605 - environment_wrapper.py - Goal reached!
2024-08-29 17:06:30,364 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:31,782 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:32,524 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:33,237 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:33,954 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:33,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:36,139 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:36,151 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:36,197 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:36,212 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:39,766 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:39,836 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:39,856 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:40,619 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:41,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:44,192 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:46,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:47,761 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:47,774 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:47,791 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:47,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:49,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:49,987 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:55,639 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:55,666 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:57,088 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:57,099 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:59,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:06:59,303 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,155 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,172 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,207 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:02,228 - father_agent.py - Average Return = -227.33749389648438
2024-08-29 17:07:02,228 - father_agent.py - Average Virtual Goal Value = -212.5
2024-08-29 17:07:02,228 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:07:02,229 - synthesizer_pomdp.py - Training agent for 2000 iterations.
2024-08-29 17:07:02,308 - father_agent.py - Training agent
2024-08-29 17:07:02,721 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:02,967 - father_agent.py - Step: 0, Training loss: 7.322464466094971
2024-08-29 17:07:04,715 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:06,155 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:06,167 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:06,179 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:06,897 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:08,327 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:16,098 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:16,106 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:20,368 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:20,442 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:21,875 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:21,895 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:21,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:22,643 - father_agent.py - Average Return = -267.625
2024-08-29 17:07:22,643 - father_agent.py - Average Virtual Goal Value = -162.5
2024-08-29 17:07:22,643 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:07:22,694 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:22,775 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:22,839 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:22,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:22,947 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:23,018 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:23,105 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,158 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:23,298 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,356 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,366 - father_agent.py - Step: 10, Training loss: 207.22735595703125
2024-08-29 17:07:23,467 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,555 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,596 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:23,714 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,771 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:23,890 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,936 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:23,981 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:24,035 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:24,062 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:24,072 - father_agent.py - Step: 20, Training loss: 267.6068115234375
2024-08-29 17:07:25,344 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,406 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:25,493 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,526 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:25,562 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:25,619 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,718 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,808 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,886 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:25,896 - father_agent.py - Step: 30, Training loss: 266.6236572265625
2024-08-29 17:07:25,978 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,026 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:26,115 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,146 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:26,218 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,321 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:26,372 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:26,441 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,550 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,689 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,699 - father_agent.py - Step: 40, Training loss: 266.677734375
2024-08-29 17:07:26,835 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,877 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:26,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:27,054 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:27,151 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:27,210 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:27,262 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:27,301 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:27,349 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:28,560 - father_agent.py - Step: 50, Training loss: 313.20831298828125
2024-08-29 17:07:28,599 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:28,651 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:28,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:28,791 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:28,884 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:28,949 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:28,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:29,036 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,151 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,300 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,310 - father_agent.py - Step: 60, Training loss: 251.02688598632812
2024-08-29 17:07:29,364 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,432 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,503 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,542 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:29,599 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,649 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:29,741 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:29,774 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:29,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:29,828 - father_agent.py - Step: 70, Training loss: 250.58543395996094
2024-08-29 17:07:29,848 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,097 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:31,199 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:31,323 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:31,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,434 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,518 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,566 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,628 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,638 - father_agent.py - Step: 80, Training loss: 234.79644775390625
2024-08-29 17:07:31,649 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,757 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:31,808 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,832 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,870 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:31,994 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,039 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,078 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:32,141 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,302 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,313 - father_agent.py - Step: 90, Training loss: 375.2007141113281
2024-08-29 17:07:32,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:32,421 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,443 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:32,497 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,625 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,774 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,802 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:32,841 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:32,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:07:32,998 - father_agent.py - Step: 100, Training loss: 250.72216796875
2024-08-29 17:07:43,253 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:43,265 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:44,716 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:46,867 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:46,899 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:48,322 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:48,330 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:54,717 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:54,744 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:55,478 - father_agent.py - Average Return = -302.79998779296875
2024-08-29 17:07:55,478 - father_agent.py - Average Virtual Goal Value = -112.5
2024-08-29 17:07:55,478 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:07:55,656 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:56,099 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:56,158 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:07:56,181 - father_agent.py - Step: 110, Training loss: 250.6056671142578
2024-08-29 17:07:56,873 - father_agent.py - Step: 120, Training loss: 251.28883361816406
2024-08-29 17:07:57,568 - father_agent.py - Step: 130, Training loss: 235.85601806640625
2024-08-29 17:07:58,257 - father_agent.py - Step: 140, Training loss: 157.53955078125
2024-08-29 17:07:58,957 - father_agent.py - Step: 150, Training loss: 360.5708312988281
2024-08-29 17:07:59,648 - father_agent.py - Step: 160, Training loss: 204.4526824951172
2024-08-29 17:08:00,344 - father_agent.py - Step: 170, Training loss: 188.84207153320312
2024-08-29 17:08:01,044 - father_agent.py - Step: 180, Training loss: 220.29718017578125
2024-08-29 17:08:01,742 - father_agent.py - Step: 190, Training loss: 299.0480651855469
2024-08-29 17:08:01,776 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:02,439 - father_agent.py - Step: 200, Training loss: 236.9011993408203
2024-08-29 17:08:04,903 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:10,666 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:10,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:19,174 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:19,186 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:19,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:24,183 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:24,924 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:25,661 - father_agent.py - Average Return = -314.125
2024-08-29 17:08:25,661 - father_agent.py - Average Virtual Goal Value = -100.0
2024-08-29 17:08:25,661 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:08:25,698 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:26,255 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:26,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:26,333 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:26,371 - father_agent.py - Step: 210, Training loss: 142.61138916015625
2024-08-29 17:08:27,065 - father_agent.py - Step: 220, Training loss: 111.84188842773438
2024-08-29 17:08:27,739 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:27,765 - father_agent.py - Step: 230, Training loss: 96.00297546386719
2024-08-29 17:08:28,453 - father_agent.py - Step: 240, Training loss: 205.4244384765625
2024-08-29 17:08:29,143 - father_agent.py - Step: 250, Training loss: 141.75082397460938
2024-08-29 17:08:29,832 - father_agent.py - Step: 260, Training loss: 158.30775451660156
2024-08-29 17:08:30,525 - father_agent.py - Step: 270, Training loss: 95.49937438964844
2024-08-29 17:08:31,215 - father_agent.py - Step: 280, Training loss: 95.7430419921875
2024-08-29 17:08:31,909 - father_agent.py - Step: 290, Training loss: 80.57275390625
2024-08-29 17:08:31,939 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,212 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,246 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,274 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,323 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,351 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:32,611 - father_agent.py - Step: 300, Training loss: 111.52188873291016
2024-08-29 17:08:32,925 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:38,592 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:40,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:42,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:42,172 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:42,889 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:42,899 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:44,344 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:47,928 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:49,351 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:50,069 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:53,608 - father_agent.py - Average Return = -285.7250061035156
2024-08-29 17:08:53,608 - father_agent.py - Average Virtual Goal Value = -137.5
2024-08-29 17:08:53,608 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:08:54,306 - father_agent.py - Step: 310, Training loss: 79.8493881225586
2024-08-29 17:08:54,999 - father_agent.py - Step: 320, Training loss: 126.07839965820312
2024-08-29 17:08:55,696 - father_agent.py - Step: 330, Training loss: 126.96711730957031
2024-08-29 17:08:56,393 - father_agent.py - Step: 340, Training loss: 110.31961822509766
2024-08-29 17:08:56,756 - environment_wrapper.py - Goal reached!
2024-08-29 17:08:57,090 - father_agent.py - Step: 350, Training loss: 32.24811553955078
2024-08-29 17:08:57,130 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:57,786 - father_agent.py - Step: 360, Training loss: 48.37968826293945
2024-08-29 17:08:58,476 - father_agent.py - Step: 370, Training loss: 16.416458129882812
2024-08-29 17:08:58,978 - environment_wrapper.py - Goal reached!
2024-08-29 17:08:59,174 - father_agent.py - Step: 380, Training loss: 1.0752652883529663
2024-08-29 17:08:59,435 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:59,855 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:08:59,871 - father_agent.py - Step: 390, Training loss: 1.1208641529083252
2024-08-29 17:08:59,883 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:00,074 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:00,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:00,193 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:00,292 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:00,560 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:00,583 - father_agent.py - Step: 400, Training loss: 79.84767150878906
2024-08-29 17:09:00,954 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,014 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,033 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:01,062 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:01,079 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:01,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:01,187 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:01,330 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,385 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,441 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,565 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,602 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:01,616 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,081 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,100 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,194 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:03,273 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:03,288 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,315 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,328 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:03,368 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:03,399 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:04,141 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,166 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,195 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,245 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,295 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,311 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,343 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,360 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:04,456 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:04,526 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:04,536 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:05,058 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:05,797 - father_agent.py - Average Return = -60.275001525878906
2024-08-29 17:09:05,797 - father_agent.py - Average Virtual Goal Value = -100.0
2024-08-29 17:09:05,797 - father_agent.py - Goal Reach Probability = 0.35
2024-08-29 17:09:05,957 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:05,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,025 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,040 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,159 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:06,247 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:06,262 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,340 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,363 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,445 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,531 - father_agent.py - Step: 410, Training loss: 16.210851669311523
2024-08-29 17:09:06,559 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:06,730 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,764 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:06,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:07,237 - father_agent.py - Step: 420, Training loss: 109.97543334960938
2024-08-29 17:09:07,932 - father_agent.py - Step: 430, Training loss: 33.048248291015625
2024-08-29 17:09:08,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:08,628 - father_agent.py - Step: 440, Training loss: 63.352088928222656
2024-08-29 17:09:09,317 - father_agent.py - Step: 450, Training loss: 63.613006591796875
2024-08-29 17:09:09,768 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:10,015 - father_agent.py - Step: 460, Training loss: 47.248558044433594
2024-08-29 17:09:10,709 - father_agent.py - Step: 470, Training loss: 63.65357208251953
2024-08-29 17:09:11,298 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:11,407 - father_agent.py - Step: 480, Training loss: 94.255859375
2024-08-29 17:09:11,409 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:12,102 - father_agent.py - Step: 490, Training loss: 16.700817108154297
2024-08-29 17:09:12,534 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:12,795 - father_agent.py - Step: 500, Training loss: 78.69601440429688
2024-08-29 17:09:13,102 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:13,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:13,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:16,751 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:18,896 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:18,914 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:18,960 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:19,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:24,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:24,738 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:27,590 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:27,606 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:30,446 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:31,894 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:31,896 - father_agent.py - Average Return = -257.04998779296875
2024-08-29 17:09:31,896 - father_agent.py - Average Virtual Goal Value = -175.0
2024-08-29 17:09:31,896 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:09:32,595 - father_agent.py - Step: 510, Training loss: 79.324462890625
2024-08-29 17:09:33,288 - father_agent.py - Step: 520, Training loss: 63.962425231933594
2024-08-29 17:09:33,376 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:33,988 - father_agent.py - Step: 530, Training loss: 32.38977813720703
2024-08-29 17:09:34,682 - father_agent.py - Step: 540, Training loss: 94.52261352539062
2024-08-29 17:09:34,801 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:35,383 - father_agent.py - Step: 550, Training loss: 125.43997955322266
2024-08-29 17:09:36,080 - father_agent.py - Step: 560, Training loss: 95.159912109375
2024-08-29 17:09:36,245 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:36,370 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:36,455 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:36,492 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:36,604 - environment_wrapper.py - Goal reached!
2024-08-29 17:09:36,686 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:36,793 - father_agent.py - Step: 570, Training loss: 78.76484680175781
2024-08-29 17:09:37,488 - father_agent.py - Step: 580, Training loss: 110.37129974365234
2024-08-29 17:09:38,188 - father_agent.py - Step: 590, Training loss: 48.444732666015625
2024-08-29 17:09:38,433 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:38,511 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:38,885 - father_agent.py - Step: 600, Training loss: 48.60883331298828
2024-08-29 17:09:39,897 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:41,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:42,061 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:44,972 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:46,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:48,628 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:51,614 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:53,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:54,515 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:54,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:54,547 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:55,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:55,382 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:56,197 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:56,944 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,040 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,042 - father_agent.py - Average Return = -237.10000610351562
2024-08-29 17:09:57,042 - father_agent.py - Average Virtual Goal Value = -200.0
2024-08-29 17:09:57,042 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:09:57,104 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,176 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,208 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,333 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,455 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:57,758 - father_agent.py - Step: 610, Training loss: 78.65543365478516
2024-08-29 17:09:58,454 - father_agent.py - Step: 620, Training loss: 109.97163391113281
2024-08-29 17:09:59,158 - father_agent.py - Step: 630, Training loss: 33.05519104003906
2024-08-29 17:09:59,202 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:59,858 - father_agent.py - Step: 640, Training loss: 140.9853973388672
2024-08-29 17:09:59,870 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:09:59,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:00,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:00,234 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:00,272 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:00,568 - father_agent.py - Step: 650, Training loss: 65.43014526367188
2024-08-29 17:10:01,260 - father_agent.py - Step: 660, Training loss: 16.710166931152344
2024-08-29 17:10:01,694 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:01,721 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:01,971 - father_agent.py - Step: 670, Training loss: 79.20263671875
2024-08-29 17:10:02,664 - father_agent.py - Step: 680, Training loss: 31.2401123046875
2024-08-29 17:10:02,810 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:03,364 - father_agent.py - Step: 690, Training loss: 46.74461364746094
2024-08-29 17:10:03,373 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:03,498 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:04,077 - father_agent.py - Step: 700, Training loss: 78.49313354492188
2024-08-29 17:10:05,133 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:12,322 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:12,366 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:15,209 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:15,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:18,868 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:21,704 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:23,844 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:24,575 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:26,713 - father_agent.py - Average Return = -307.04998779296875
2024-08-29 17:10:26,713 - father_agent.py - Average Virtual Goal Value = -112.5
2024-08-29 17:10:26,713 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:10:27,422 - father_agent.py - Step: 710, Training loss: 48.24045944213867
2024-08-29 17:10:28,123 - father_agent.py - Step: 720, Training loss: 47.06676483154297
2024-08-29 17:10:28,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,210 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,285 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,440 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,455 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,502 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:28,839 - father_agent.py - Step: 730, Training loss: 63.22557830810547
2024-08-29 17:10:29,006 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:29,539 - father_agent.py - Step: 740, Training loss: 125.19937133789062
2024-08-29 17:10:30,235 - father_agent.py - Step: 750, Training loss: 110.42549896240234
2024-08-29 17:10:30,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:30,734 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:30,942 - father_agent.py - Step: 760, Training loss: 62.99388122558594
2024-08-29 17:10:31,036 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:31,640 - father_agent.py - Step: 770, Training loss: 109.2708740234375
2024-08-29 17:10:32,335 - father_agent.py - Step: 780, Training loss: 46.61091995239258
2024-08-29 17:10:33,031 - father_agent.py - Step: 790, Training loss: 31.009286880493164
2024-08-29 17:10:33,723 - father_agent.py - Step: 800, Training loss: 62.76939010620117
2024-08-29 17:10:38,295 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:39,752 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:44,021 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:45,459 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:46,895 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:48,383 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:48,441 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:48,523 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:49,269 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:54,266 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:55,677 - father_agent.py - Average Return = -295.1499938964844
2024-08-29 17:10:55,677 - father_agent.py - Average Virtual Goal Value = -125.0
2024-08-29 17:10:55,677 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:10:55,758 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:56,251 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:10:56,380 - father_agent.py - Step: 810, Training loss: 109.62394714355469
2024-08-29 17:10:57,075 - father_agent.py - Step: 820, Training loss: 63.13036346435547
2024-08-29 17:10:57,774 - father_agent.py - Step: 830, Training loss: 77.46913146972656
2024-08-29 17:10:58,469 - father_agent.py - Step: 840, Training loss: 78.7900619506836
2024-08-29 17:10:59,168 - father_agent.py - Step: 850, Training loss: 31.203128814697266
2024-08-29 17:10:59,861 - father_agent.py - Step: 860, Training loss: 0.6951967477798462
2024-08-29 17:11:00,285 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:00,559 - father_agent.py - Step: 870, Training loss: 93.68036651611328
2024-08-29 17:11:01,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:01,255 - father_agent.py - Step: 880, Training loss: 31.746994018554688
2024-08-29 17:11:01,949 - father_agent.py - Step: 890, Training loss: 0.056990109384059906
2024-08-29 17:11:02,645 - father_agent.py - Step: 900, Training loss: 48.50845718383789
2024-08-29 17:11:02,946 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:03,711 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:03,719 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:04,457 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:07,313 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:07,332 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:08,804 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:08,817 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:09,617 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:11,139 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:16,135 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:18,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,031 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,046 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,074 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,098 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,821 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:19,824 - father_agent.py - Average Return = -228.60000610351562
2024-08-29 17:11:19,824 - father_agent.py - Average Virtual Goal Value = -212.5
2024-08-29 17:11:19,824 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:11:20,528 - father_agent.py - Step: 910, Training loss: 77.65283203125
2024-08-29 17:11:21,229 - father_agent.py - Step: 920, Training loss: 46.90376281738281
2024-08-29 17:11:21,293 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:21,810 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:21,838 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:21,933 - father_agent.py - Step: 930, Training loss: 32.027591705322266
2024-08-29 17:11:21,942 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:22,630 - father_agent.py - Step: 940, Training loss: 46.90285873413086
2024-08-29 17:11:23,327 - father_agent.py - Step: 950, Training loss: 15.985591888427734
2024-08-29 17:11:24,025 - father_agent.py - Step: 960, Training loss: 47.15230941772461
2024-08-29 17:11:24,722 - father_agent.py - Step: 970, Training loss: 46.96547317504883
2024-08-29 17:11:24,774 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:24,808 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:24,830 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:25,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:25,338 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:25,366 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:25,435 - father_agent.py - Step: 980, Training loss: 46.99131774902344
2024-08-29 17:11:26,131 - father_agent.py - Step: 990, Training loss: 15.605670928955078
2024-08-29 17:11:26,828 - father_agent.py - Step: 1000, Training loss: 15.96612548828125
2024-08-29 17:11:29,944 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:31,369 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:39,840 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:41,337 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:41,352 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:43,498 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:45,632 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:45,661 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:45,678 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:47,099 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:47,133 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:47,837 - father_agent.py - Average Return = -286.25
2024-08-29 17:11:47,837 - father_agent.py - Average Virtual Goal Value = -137.5
2024-08-29 17:11:47,837 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:11:48,541 - father_agent.py - Step: 1010, Training loss: 32.19981384277344
2024-08-29 17:11:49,245 - father_agent.py - Step: 1020, Training loss: 31.825260162353516
2024-08-29 17:11:49,320 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:49,948 - father_agent.py - Step: 1030, Training loss: 32.07904815673828
2024-08-29 17:11:50,649 - father_agent.py - Step: 1040, Training loss: 15.770333290100098
2024-08-29 17:11:51,349 - father_agent.py - Step: 1050, Training loss: 15.754687309265137
2024-08-29 17:11:52,043 - father_agent.py - Step: 1060, Training loss: 32.26765823364258
2024-08-29 17:11:52,744 - father_agent.py - Step: 1070, Training loss: 15.741151809692383
2024-08-29 17:11:52,753 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:53,313 - environment_wrapper.py - Goal reached!
2024-08-29 17:11:53,392 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:53,442 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:53,449 - father_agent.py - Step: 1080, Training loss: 0.8990058302879333
2024-08-29 17:11:53,533 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:53,548 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:54,150 - father_agent.py - Step: 1090, Training loss: 0.02452763542532921
2024-08-29 17:11:54,846 - father_agent.py - Step: 1100, Training loss: 62.0711555480957
2024-08-29 17:11:57,287 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:58,733 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:11:59,454 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:01,587 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:01,608 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:03,052 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:03,819 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:04,544 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:06,757 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:06,766 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:07,516 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:08,978 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:09,006 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:09,040 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:13,304 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:13,306 - father_agent.py - Average Return = -248.52499389648438
2024-08-29 17:12:13,306 - father_agent.py - Average Virtual Goal Value = -187.5
2024-08-29 17:12:13,306 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:12:13,338 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:13,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:13,858 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:14,024 - father_agent.py - Step: 1110, Training loss: 31.58953094482422
2024-08-29 17:12:14,720 - father_agent.py - Step: 1120, Training loss: 108.68342590332031
2024-08-29 17:12:15,420 - father_agent.py - Step: 1130, Training loss: 0.2587055265903473
2024-08-29 17:12:16,114 - father_agent.py - Step: 1140, Training loss: 16.464685440063477
2024-08-29 17:12:16,683 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:16,698 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:16,714 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:16,821 - father_agent.py - Step: 1150, Training loss: 46.698917388916016
2024-08-29 17:12:17,519 - father_agent.py - Step: 1160, Training loss: 16.45375633239746
2024-08-29 17:12:18,231 - father_agent.py - Step: 1170, Training loss: 77.39442443847656
2024-08-29 17:12:18,938 - father_agent.py - Step: 1180, Training loss: 32.674747467041016
2024-08-29 17:12:19,516 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:19,569 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:19,639 - father_agent.py - Step: 1190, Training loss: 16.24808120727539
2024-08-29 17:12:20,335 - father_agent.py - Step: 1200, Training loss: 32.02239227294922
2024-08-29 17:12:20,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:20,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:24,952 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:24,971 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:27,101 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:27,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:27,903 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:27,912 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:30,049 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:32,232 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:33,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:33,701 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:35,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:35,175 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:35,961 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:37,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:38,140 - father_agent.py - Average Return = -239.4499969482422
2024-08-29 17:12:38,140 - father_agent.py - Average Virtual Goal Value = -200.0
2024-08-29 17:12:38,140 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:12:38,841 - father_agent.py - Step: 1210, Training loss: 47.59721755981445
2024-08-29 17:12:39,540 - father_agent.py - Step: 1220, Training loss: 62.236087799072266
2024-08-29 17:12:39,597 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:40,242 - father_agent.py - Step: 1230, Training loss: 62.69358825683594
2024-08-29 17:12:40,936 - father_agent.py - Step: 1240, Training loss: 0.21217307448387146
2024-08-29 17:12:41,096 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:41,637 - father_agent.py - Step: 1250, Training loss: 31.17733383178711
2024-08-29 17:12:42,337 - father_agent.py - Step: 1260, Training loss: 46.50360107421875
2024-08-29 17:12:42,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:43,046 - father_agent.py - Step: 1270, Training loss: 31.872175216674805
2024-08-29 17:12:43,195 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:43,252 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:43,751 - father_agent.py - Step: 1280, Training loss: 32.95314407348633
2024-08-29 17:12:44,445 - father_agent.py - Step: 1290, Training loss: 16.660837173461914
2024-08-29 17:12:44,453 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:44,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:44,503 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:44,603 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:44,649 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:44,677 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:45,157 - father_agent.py - Step: 1300, Training loss: 63.35702133178711
2024-08-29 17:12:45,504 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:46,342 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:46,423 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:46,590 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:46,679 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:46,766 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:46,864 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:47,657 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:47,757 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:47,835 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:47,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:47,955 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:48,055 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:48,084 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:48,864 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:48,941 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:49,004 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:49,111 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:49,135 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:49,919 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:49,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,071 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,206 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,249 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,299 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,381 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,481 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,637 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,764 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:50,800 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,843 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,864 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:50,973 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:51,082 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:51,183 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:51,206 - father_agent.py - Average Return = -70.1500015258789
2024-08-29 17:12:51,206 - father_agent.py - Average Virtual Goal Value = 175.0
2024-08-29 17:12:51,206 - father_agent.py - Goal Reach Probability = 0.625
2024-08-29 17:12:51,904 - father_agent.py - Step: 1310, Training loss: 46.911861419677734
2024-08-29 17:12:52,596 - father_agent.py - Step: 1320, Training loss: 16.23445701599121
2024-08-29 17:12:52,617 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:52,880 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:53,094 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:53,299 - father_agent.py - Step: 1330, Training loss: 48.31982421875
2024-08-29 17:12:53,993 - father_agent.py - Step: 1340, Training loss: 47.25819396972656
2024-08-29 17:12:54,531 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:54,622 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:54,659 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:54,695 - father_agent.py - Step: 1350, Training loss: 0.44670820236206055
2024-08-29 17:12:54,766 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:55,391 - father_agent.py - Step: 1360, Training loss: 1.3009495735168457
2024-08-29 17:12:55,393 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:56,088 - father_agent.py - Step: 1370, Training loss: 31.652809143066406
2024-08-29 17:12:56,783 - father_agent.py - Step: 1380, Training loss: 32.09307098388672
2024-08-29 17:12:56,876 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:56,904 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:56,976 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,044 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,119 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,228 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,301 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,503 - father_agent.py - Step: 1390, Training loss: 33.09984588623047
2024-08-29 17:12:57,635 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,688 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,857 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:57,900 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:57,972 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:58,058 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:58,211 - father_agent.py - Step: 1400, Training loss: 79.54410552978516
2024-08-29 17:12:58,564 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:59,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:59,340 - environment_wrapper.py - Goal reached!
2024-08-29 17:12:59,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:12:59,399 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:00,268 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:00,356 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:01,187 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:01,956 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:02,037 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:02,149 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:02,284 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:02,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:02,313 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:03,107 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,131 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:03,288 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,327 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:03,407 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,425 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:03,492 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,567 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,594 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:03,692 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:03,727 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:04,549 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:05,324 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:05,406 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:06,208 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:06,276 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:06,406 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:06,443 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:06,445 - father_agent.py - Average Return = -101.9749984741211
2024-08-29 17:13:06,445 - father_agent.py - Average Virtual Goal Value = 100.0
2024-08-29 17:13:06,445 - father_agent.py - Goal Reach Probability = 0.5
2024-08-29 17:13:07,144 - father_agent.py - Step: 1410, Training loss: 171.54751586914062
2024-08-29 17:13:07,840 - father_agent.py - Step: 1420, Training loss: 78.66033935546875
2024-08-29 17:13:08,251 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:08,298 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:08,542 - father_agent.py - Step: 1430, Training loss: 64.01019287109375
2024-08-29 17:13:09,018 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:09,122 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:09,241 - father_agent.py - Step: 1440, Training loss: 94.20600891113281
2024-08-29 17:13:09,312 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:09,474 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:09,695 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:09,941 - father_agent.py - Step: 1450, Training loss: 47.180355072021484
2024-08-29 17:13:09,943 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:09,962 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,018 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,132 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,210 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,254 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,285 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,517 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:10,653 - father_agent.py - Step: 1460, Training loss: 79.4512939453125
2024-08-29 17:13:11,349 - father_agent.py - Step: 1470, Training loss: 158.4007568359375
2024-08-29 17:13:11,351 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:12,045 - father_agent.py - Step: 1480, Training loss: 79.32339477539062
2024-08-29 17:13:12,726 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:12,743 - father_agent.py - Step: 1490, Training loss: 63.68718719482422
2024-08-29 17:13:12,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:12,834 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:12,852 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:13,450 - father_agent.py - Step: 1500, Training loss: 110.25418090820312
2024-08-29 17:13:13,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:14,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:25,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:27,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:28,840 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:35,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:35,315 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:35,342 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:36,768 - father_agent.py - Average Return = -313.17498779296875
2024-08-29 17:13:36,768 - father_agent.py - Average Virtual Goal Value = -100.0
2024-08-29 17:13:36,768 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:13:37,478 - father_agent.py - Step: 1510, Training loss: 78.11445617675781
2024-08-29 17:13:38,113 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:38,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:38,177 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:38,185 - father_agent.py - Step: 1520, Training loss: 63.56101608276367
2024-08-29 17:13:38,405 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:38,893 - father_agent.py - Step: 1530, Training loss: 110.94020080566406
2024-08-29 17:13:39,457 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:39,598 - father_agent.py - Step: 1540, Training loss: 94.05903625488281
2024-08-29 17:13:39,657 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:40,304 - father_agent.py - Step: 1550, Training loss: 79.48403930664062
2024-08-29 17:13:40,835 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:41,006 - father_agent.py - Step: 1560, Training loss: 109.43116760253906
2024-08-29 17:13:41,047 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:41,205 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:41,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:41,623 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:41,721 - father_agent.py - Step: 1570, Training loss: 126.85469818115234
2024-08-29 17:13:41,762 - environment_wrapper.py - Goal reached!
2024-08-29 17:13:41,870 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:42,426 - father_agent.py - Step: 1580, Training loss: 109.0752182006836
2024-08-29 17:13:43,127 - father_agent.py - Step: 1590, Training loss: 124.96941375732422
2024-08-29 17:13:43,362 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:43,835 - father_agent.py - Step: 1600, Training loss: 155.81884765625
2024-08-29 17:13:49,151 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:49,164 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:50,591 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:50,656 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:54,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:13:54,975 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:00,642 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:04,902 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:04,949 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:06,364 - father_agent.py - Average Return = -305.0249938964844
2024-08-29 17:14:06,364 - father_agent.py - Average Virtual Goal Value = -112.5
2024-08-29 17:14:06,365 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:14:07,069 - father_agent.py - Step: 1610, Training loss: 173.6746826171875
2024-08-29 17:14:07,525 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:07,773 - father_agent.py - Step: 1620, Training loss: 62.73897933959961
2024-08-29 17:14:07,861 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:08,100 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:08,476 - father_agent.py - Step: 1630, Training loss: 156.76280212402344
2024-08-29 17:14:09,178 - father_agent.py - Step: 1640, Training loss: 94.25839233398438
2024-08-29 17:14:09,640 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:09,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:09,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:09,890 - father_agent.py - Step: 1650, Training loss: 92.80211639404297
2024-08-29 17:14:09,933 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:10,588 - father_agent.py - Step: 1660, Training loss: 125.69932556152344
2024-08-29 17:14:10,980 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:11,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:11,288 - father_agent.py - Step: 1670, Training loss: 125.92147827148438
2024-08-29 17:14:11,982 - father_agent.py - Step: 1680, Training loss: 62.50518035888672
2024-08-29 17:14:12,682 - father_agent.py - Step: 1690, Training loss: 63.944210052490234
2024-08-29 17:14:12,858 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:13,376 - father_agent.py - Step: 1700, Training loss: 15.365140914916992
2024-08-29 17:14:13,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:13,703 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:15,863 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:15,945 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:16,712 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:17,430 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:18,971 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:19,773 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:19,825 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:19,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:19,942 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:20,111 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:20,951 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:21,036 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:21,118 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:21,230 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:23,875 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:24,690 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:26,881 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:30,017 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:30,019 - father_agent.py - Average Return = -220.77499389648438
2024-08-29 17:14:30,019 - father_agent.py - Average Virtual Goal Value = 75.0
2024-08-29 17:14:30,019 - father_agent.py - Goal Reach Probability = 0.325
2024-08-29 17:14:30,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:30,265 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:30,723 - father_agent.py - Step: 1710, Training loss: 94.93125915527344
2024-08-29 17:14:30,868 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:31,161 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:31,176 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:31,368 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:31,429 - father_agent.py - Step: 1720, Training loss: 31.89460563659668
2024-08-29 17:14:31,431 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:32,129 - father_agent.py - Step: 1730, Training loss: 62.894935607910156
2024-08-29 17:14:32,826 - father_agent.py - Step: 1740, Training loss: 79.4280776977539
2024-08-29 17:14:33,528 - father_agent.py - Step: 1750, Training loss: 94.19058227539062
2024-08-29 17:14:33,949 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:34,050 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:34,132 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:34,173 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:34,236 - father_agent.py - Step: 1760, Training loss: 109.84696960449219
2024-08-29 17:14:34,462 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:34,941 - father_agent.py - Step: 1770, Training loss: 31.774749755859375
2024-08-29 17:14:35,441 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:35,517 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:35,640 - father_agent.py - Step: 1780, Training loss: 31.145610809326172
2024-08-29 17:14:35,854 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:36,339 - father_agent.py - Step: 1790, Training loss: 78.00909423828125
2024-08-29 17:14:37,033 - father_agent.py - Step: 1800, Training loss: 47.23160934448242
2024-08-29 17:14:38,766 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:43,742 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:43,777 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:43,861 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:43,878 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:44,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:46,096 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:46,136 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:46,155 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:46,174 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:51,166 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:51,891 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:52,621 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:52,643 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:54,082 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:54,099 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:54,112 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:54,115 - father_agent.py - Average Return = -228.97500610351562
2024-08-29 17:14:54,115 - father_agent.py - Average Virtual Goal Value = -212.5
2024-08-29 17:14:54,115 - father_agent.py - Goal Reach Probability = 0.0
2024-08-29 17:14:54,680 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:54,817 - father_agent.py - Step: 1810, Training loss: 47.67992401123047
2024-08-29 17:14:55,148 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:55,515 - father_agent.py - Step: 1820, Training loss: 79.18998718261719
2024-08-29 17:14:56,212 - father_agent.py - Step: 1830, Training loss: 47.67377471923828
2024-08-29 17:14:56,608 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:56,912 - father_agent.py - Step: 1840, Training loss: 47.55393600463867
2024-08-29 17:14:57,614 - father_agent.py - Step: 1850, Training loss: 78.57313537597656
2024-08-29 17:14:58,062 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:58,131 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:58,315 - father_agent.py - Step: 1860, Training loss: 63.663639068603516
2024-08-29 17:14:58,789 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:58,881 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:59,020 - father_agent.py - Step: 1870, Training loss: 16.06654167175293
2024-08-29 17:14:59,117 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:59,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:14:59,347 - environment_wrapper.py - Goal reached!
2024-08-29 17:14:59,727 - father_agent.py - Step: 1880, Training loss: 47.35530090332031
2024-08-29 17:15:00,419 - father_agent.py - Step: 1890, Training loss: 62.52793884277344
2024-08-29 17:15:00,901 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:01,118 - father_agent.py - Step: 1900, Training loss: 95.25112915039062
2024-08-29 17:15:01,463 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:01,626 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,372 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,430 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,479 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,581 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,657 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,756 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,828 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,915 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:02,924 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,932 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:02,996 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:03,795 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:04,575 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:04,672 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:04,729 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:04,800 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:04,927 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:05,691 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:05,787 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:05,856 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:08,134 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:08,859 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:08,924 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:09,016 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:09,092 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:09,130 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:09,157 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:09,275 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:09,987 - father_agent.py - Average Return = -112.30000305175781
2024-08-29 17:15:09,987 - father_agent.py - Average Virtual Goal Value = 137.5
2024-08-29 17:15:09,987 - father_agent.py - Goal Reach Probability = 0.525
2024-08-29 17:15:10,011 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:10,125 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:10,197 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:10,232 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:10,698 - father_agent.py - Step: 1910, Training loss: 0.43571558594703674
2024-08-29 17:15:11,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:11,395 - father_agent.py - Step: 1920, Training loss: 32.13154220581055
2024-08-29 17:15:11,425 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:12,093 - father_agent.py - Step: 1930, Training loss: 16.67952537536621
2024-08-29 17:15:12,792 - father_agent.py - Step: 1940, Training loss: 31.86711883544922
2024-08-29 17:15:12,853 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:12,926 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:13,496 - father_agent.py - Step: 1950, Training loss: 125.75735473632812
2024-08-29 17:15:14,192 - father_agent.py - Step: 1960, Training loss: 31.983835220336914
2024-08-29 17:15:14,746 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:14,778 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:14,803 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:14,835 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:14,905 - father_agent.py - Step: 1970, Training loss: 63.0243034362793
2024-08-29 17:15:15,049 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:15,591 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:15,607 - father_agent.py - Step: 1980, Training loss: 93.36601257324219
2024-08-29 17:15:15,749 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:16,307 - father_agent.py - Step: 1990, Training loss: 32.80060577392578
2024-08-29 17:15:16,818 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:16,902 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:17,251 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:17,277 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:18,729 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:19,560 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:19,587 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,332 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,364 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,460 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:20,542 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:20,623 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:20,701 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:20,711 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,748 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,794 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:20,835 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,865 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:20,922 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:21,008 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:21,088 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:21,900 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:21,967 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:22,058 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:22,813 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:22,834 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:22,884 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:22,974 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:23,049 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:24,535 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:25,300 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:25,358 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:25,386 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:26,181 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:26,318 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:26,387 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:26,470 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:26,570 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:26,626 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:27,373 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:27,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:27,475 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:28,248 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:29,070 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:29,082 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:29,168 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:29,232 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:29,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:29,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:30,054 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:30,095 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:30,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:30,143 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:30,219 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:30,261 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:30,269 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:31,103 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:31,210 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:31,958 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:31,989 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:33,454 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:33,471 - environment_wrapper.py - Ended, but not in a goal state: []
2024-08-29 17:15:33,586 - environment_wrapper.py - Goal reached!
2024-08-29 17:15:34,300 - father_agent.py - Average Return = -110.36250305175781
2024-08-29 17:15:34,300 - father_agent.py - Average Virtual Goal Value = 43.75
2024-08-29 17:15:34,300 - father_agent.py - Goal Reach Probability = 0.425

------------------------------------

PAYNT results: 
0.5694957103184766
controller size: 14

Storm results: 
0.6167333800017228
controller size: 10739

------------------------------------

