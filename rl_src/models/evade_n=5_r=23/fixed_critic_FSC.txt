2024-09-03 11:58:05,375 - cli.py - This is Paynt version 0.1.0.
2024-09-03 11:58:05,375 - sketch.py - loading sketch from rl_src/models/evade_n=5_r=23/sketch.templ ...
2024-09-03 11:58:05,375 - sketch.py - assuming sketch in PRISM format...
2024-09-03 11:58:05,383 - prism_parser.py - PRISM model type: POMDP
2024-09-03 11:58:05,383 - prism_parser.py - loading properties from rl_src/models/evade_n=5_r=23/sketch.props ...
2024-09-03 11:58:05,384 - prism_parser.py - found the following specification: optimality: R{"steps"}min=? [F "goal"] 
2024-09-03 11:58:05,431 - sketch.py - sketch parsing OK
2024-09-03 11:58:05,433 - sketch.py - converting state rewards 'steps' to state-action rewards
2024-09-03 11:58:05,435 - sketch.py - constructed explicit quotient having 1961 states and 5801 actions
2024-09-03 11:58:05,435 - sketch.py - found the following specification optimality: R{"steps"}min=? [F "goal"] 
2024-09-03 11:58:05,436 - pomdp.py - constructed POMDP having 981 observations.
2024-09-03 11:58:05,445 - pomdp.py - unfolding 1-FSC template into POMDP...
2024-09-03 11:58:05,447 - pomdp.py - constructed quotient MDP having 1961 states and 5801 actions.
2024-09-03 11:58:06,459 - tpu_cluster_resolver.py - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-09-03 11:58:06,703 - __init__.py - Creating converter from 7 to 5
2024-09-03 11:58:06,703 - __init__.py - Creating converter from 5 to 7
2024-09-03 11:58:06,703 - __init__.py - Creating converter from 7 to 5
2024-09-03 11:58:06,703 - __init__.py - Creating converter from 5 to 7
2024-09-03 11:58:07,816 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-09-03 11:58:07,816 - synthesizer_pomdp.py - Storm settings: iterative - (150, 10, 7), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False
2024-09-03 11:58:07,822 - synthesizer_pomdp.py - Timeout for PAYNT started
-----------PAYNT-----------                     
Value = 17.0 | Time elapsed = 0.0s | FSC size = 1962

2024-09-03 11:58:07,823 - synthesizer.py - double-checking specification satisfiability:  : 17.0
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.01 s
number of holes: 480, family size: 1e335, quotient: 1961 states / 5801 actions
explored: 100 %
MDP stats: avg MDP size: 1961, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:07,860 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:07,860 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-09-03 11:58:07,867 - pomdp.py - constructed quotient MDP having 3921 states and 23202 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.01 s
number of holes: 2921, family size: 1e1261, quotient: 3921 states / 23202 actions
explored: 100 %
MDP stats: avg MDP size: 3921, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:08,064 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:08,064 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:08,066 - pomdp.py - unfolding 3-FSC template into POMDP...
2024-09-03 11:58:08,074 - pomdp.py - constructed quotient MDP having 5881 states and 52203 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.02 s
number of holes: 4381, family size: 1e2409, quotient: 5881 states / 52203 actions
explored: 100 %
MDP stats: avg MDP size: 5881, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:08,327 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:08,328 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:08,331 - pomdp.py - unfolding 4-FSC template into POMDP...
2024-09-03 11:58:08,349 - pomdp.py - constructed quotient MDP having 7841 states and 92804 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.03 s
number of holes: 5841, family size: 1e3702, quotient: 7841 states / 92804 actions
explored: 100 %
MDP stats: avg MDP size: 7841, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:08,653 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:08,653 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:08,660 - pomdp.py - unfolding 5-FSC template into POMDP...
2024-09-03 11:58:09,019 - pomdp.py - constructed quotient MDP having 9801 states and 145005 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.04 s
number of holes: 7301, family size: 1e5103, quotient: 9801 states / 145005 actions
explored: 100 %
MDP stats: avg MDP size: 9801, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:09,444 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:09,444 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:09,453 - pomdp.py - unfolding 6-FSC template into POMDP...
2024-09-03 11:58:09,670 - pomdp.py - constructed quotient MDP having 11761 states and 208806 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.06 s
number of holes: 8761, family size: 1e6589, quotient: 11761 states / 208806 actions
explored: 100 %
MDP stats: avg MDP size: 11761, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:10,413 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:10,413 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:10,425 - pomdp.py - unfolding 7-FSC template into POMDP...
2024-09-03 11:58:10,672 - pomdp.py - constructed quotient MDP having 13721 states and 284207 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.09 s
number of holes: 10221, family size: 1e8146, quotient: 13721 states / 284207 actions
explored: 100 %
MDP stats: avg MDP size: 13721, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:11,598 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:11,599 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:11,616 - pomdp.py - unfolding 8-FSC template into POMDP...
2024-09-03 11:58:11,889 - pomdp.py - constructed quotient MDP having 15681 states and 371208 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.11 s
number of holes: 11681, family size: 1e9765, quotient: 15681 states / 371208 actions
explored: 100 %
MDP stats: avg MDP size: 15681, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:12,985 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:12,985 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:13,008 - pomdp.py - unfolding 9-FSC template into POMDP...
2024-09-03 11:58:13,515 - pomdp.py - constructed quotient MDP having 17641 states and 469809 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.14 s
number of holes: 13141, family size: 1e11436, quotient: 17641 states / 469809 actions
explored: 100 %
MDP stats: avg MDP size: 17641, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:14,827 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:14,828 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:14,857 - pomdp.py - unfolding 10-FSC template into POMDP...
2024-09-03 11:58:15,195 - pomdp.py - constructed quotient MDP having 19601 states and 580010 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.18 s
number of holes: 14601, family size: 1e13156, quotient: 19601 states / 580010 actions
explored: 100 %
MDP stats: avg MDP size: 19601, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:16,975 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:16,975 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:17,010 - pomdp.py - unfolding 11-FSC template into POMDP...
2024-09-03 11:58:17,616 - pomdp.py - constructed quotient MDP having 21561 states and 701811 actions.
2024-09-03 11:58:19,149 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:58:19,190 - storm_pomdp_control.py - Interactive Storm started
2024-09-03 11:58:19,191 - storm_pomdp_control.py - starting Storm POMDP analysis
Finished exploring under-approximation MDP.
Start analysis...
2024-09-03 11:58:27,199 - storm_pomdp_control.py - Pausing Storm
-----------Storm-----------               
Value = 17.0 | Time elapsed = 19.4s | FSC size = 1522


------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:58:27,252 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:58:28,158 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:58:28,158 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.23 s
number of holes: 16061, family size: 1e14917, quotient: 21561 states / 701811 actions
explored: 100 %
MDP stats: avg MDP size: 21561, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:28,397 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:28,397 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:28,442 - pomdp.py - unfolding 12-FSC template into POMDP...
2024-09-03 11:58:29,104 - pomdp.py - constructed quotient MDP having 23521 states and 835212 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.3 s
number of holes: 17521, family size: 1e16718, quotient: 23521 states / 835212 actions
explored: 100 %
MDP stats: avg MDP size: 23521, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:31,604 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:31,605 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:31,659 - pomdp.py - unfolding 13-FSC template into POMDP...
2024-09-03 11:58:32,670 - pomdp.py - constructed quotient MDP having 25481 states and 980213 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.36 s
number of holes: 18981, family size: 1e18554, quotient: 25481 states / 980213 actions
explored: 100 %
MDP stats: avg MDP size: 25481, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:35,208 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:35,209 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:35,272 - pomdp.py - unfolding 14-FSC template into POMDP...
2024-09-03 11:58:36,105 - pomdp.py - constructed quotient MDP having 27441 states and 1136814 actions.
2024-09-03 11:58:39,074 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:58:39,157 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:58:39,158 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:58:39,167 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:58:40,075 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:58:40,075 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.43 s
number of holes: 20441, family size: 1e20423, quotient: 27441 states / 1136814 actions
explored: 100 %
MDP stats: avg MDP size: 27441, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:40,507 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:40,508 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:40,581 - pomdp.py - unfolding 15-FSC template into POMDP...
2024-09-03 11:58:41,506 - pomdp.py - constructed quotient MDP having 29401 states and 1305015 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.49 s
number of holes: 21901, family size: 1e22322, quotient: 29401 states / 1305015 actions
explored: 100 %
MDP stats: avg MDP size: 29401, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:44,901 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:44,901 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:44,993 - pomdp.py - unfolding 16-FSC template into POMDP...
2024-09-03 11:58:46,284 - pomdp.py - constructed quotient MDP having 31361 states and 1484816 actions.
2024-09-03 11:58:49,626 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:58:49,705 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:58:49,705 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:58:49,714 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:58:50,627 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:58:50,627 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.55 s
number of holes: 23361, family size: 1e24249, quotient: 31361 states / 1484816 actions
explored: 100 %
MDP stats: avg MDP size: 31361, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:51,192 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:51,192 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:51,283 - pomdp.py - unfolding 17-FSC template into POMDP...
2024-09-03 11:58:52,662 - pomdp.py - constructed quotient MDP having 33321 states and 1676217 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.62 s
number of holes: 24821, family size: 1e26204, quotient: 33321 states / 1676217 actions
explored: 100 %
MDP stats: avg MDP size: 33321, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:58:56,770 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:58:56,770 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:58:56,872 - pomdp.py - unfolding 18-FSC template into POMDP...
2024-09-03 11:58:58,316 - pomdp.py - constructed quotient MDP having 35281 states and 1879218 actions.
2024-09-03 11:59:02,871 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:59:02,945 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:59:02,945 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:59:02,955 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:59:03,873 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:59:03,873 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.68 s
number of holes: 26281, family size: 1e28183, quotient: 35281 states / 1879218 actions
explored: 100 %
MDP stats: avg MDP size: 35281, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:04,563 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:04,564 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:04,680 - pomdp.py - unfolding 19-FSC template into POMDP...
2024-09-03 11:59:06,296 - pomdp.py - constructed quotient MDP having 37241 states and 2093819 actions.
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.76 s
number of holes: 27741, family size: 1e30186, quotient: 37241 states / 2093819 actions
explored: 100 %
MDP stats: avg MDP size: 37241, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:12,209 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:12,209 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:12,340 - pomdp.py - unfolding 20-FSC template into POMDP...
2024-09-03 11:59:13,764 - pomdp.py - constructed quotient MDP having 39201 states and 2320020 actions.
2024-09-03 11:59:19,445 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:59:19,512 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:59:19,512 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:59:19,522 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:59:20,446 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:59:20,446 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.84 s
number of holes: 29201, family size: 1e32211, quotient: 39201 states / 2320020 actions
explored: 100 %
MDP stats: avg MDP size: 39201, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:21,289 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:21,289 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:21,432 - pomdp.py - unfolding 21-FSC template into POMDP...
2024-09-03 11:59:22,958 - pomdp.py - constructed quotient MDP having 41161 states and 2557821 actions.
2024-09-03 11:59:29,814 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:59:29,877 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:59:29,877 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:59:29,887 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:59:30,815 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:59:30,815 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.92 s
number of holes: 30661, family size: 1e34258, quotient: 41161 states / 2557821 actions
explored: 100 %
MDP stats: avg MDP size: 41161, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:31,739 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:31,740 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:31,894 - pomdp.py - unfolding 22-FSC template into POMDP...
2024-09-03 11:59:33,640 - pomdp.py - constructed quotient MDP having 43121 states and 2807222 actions.
2024-09-03 11:59:40,791 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:59:40,851 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:59:40,851 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:59:40,860 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:59:41,792 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:59:41,792 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 1.0 s
number of holes: 32121, family size: 1e36325, quotient: 43121 states / 2807222 actions
explored: 100 %
MDP stats: avg MDP size: 43121, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:42,805 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:42,805 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:42,974 - pomdp.py - unfolding 23-FSC template into POMDP...
2024-09-03 11:59:44,861 - pomdp.py - constructed quotient MDP having 45081 states and 3068223 actions.
2024-09-03 11:59:51,351 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 11:59:51,406 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 11:59:51,407 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 11:59:51,416 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 11:59:52,352 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 11:59:52,352 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 1.11 s
number of holes: 33581, family size: 1e38411, quotient: 45081 states / 3068223 actions
explored: 100 %
MDP stats: avg MDP size: 45081, iterations: 1

optimum: 17.0
--------------------
2024-09-03 11:59:53,471 - synthesizer_pomdp.py - Assignment is None
2024-09-03 11:59:53,472 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 11:59:53,656 - pomdp.py - unfolding 24-FSC template into POMDP...
2024-09-03 11:59:56,047 - pomdp.py - constructed quotient MDP having 47041 states and 3340824 actions.
2024-09-03 12:00:04,073 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 12:00:04,125 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 12:00:04,125 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 12:00:04,134 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 12:00:05,075 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 12:00:05,075 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 1.18 s
number of holes: 35041, family size: 1e40516, quotient: 47041 states / 3340824 actions
explored: 100 %
MDP stats: avg MDP size: 47041, iterations: 1

optimum: 17.0
--------------------
2024-09-03 12:00:06,265 - synthesizer_pomdp.py - Assignment is None
2024-09-03 12:00:06,266 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 12:00:06,478 - pomdp.py - unfolding 25-FSC template into POMDP...
2024-09-03 12:00:08,989 - pomdp.py - constructed quotient MDP having 49001 states and 3625025 actions.
2024-09-03 12:00:17,409 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 12:00:17,455 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 12:00:17,456 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 12:00:17,465 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 12:00:18,410 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 12:00:18,410 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 1.27 s
number of holes: 36501, family size: 1e42638, quotient: 49001 states / 3625025 actions
explored: 100 %
MDP stats: avg MDP size: 49001, iterations: 1

optimum: 17.0
--------------------
2024-09-03 12:00:19,690 - synthesizer_pomdp.py - Assignment is None
2024-09-03 12:00:19,690 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 12:00:19,906 - pomdp.py - unfolding 26-FSC template into POMDP...
2024-09-03 12:00:22,730 - pomdp.py - constructed quotient MDP having 50961 states and 3920826 actions.
2024-09-03 12:00:32,481 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 12:00:32,522 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 12:00:32,523 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 12:00:32,532 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 12:00:33,482 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 12:00:33,482 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 1.38 s
number of holes: 37961, family size: 1e44778, quotient: 50961 states / 3920826 actions
explored: 100 %
MDP stats: avg MDP size: 50961, iterations: 1

optimum: 17.0
--------------------
2024-09-03 12:00:34,871 - synthesizer_pomdp.py - Assignment is None
2024-09-03 12:00:34,871 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-09-03 12:00:35,114 - pomdp.py - unfolding 27-FSC template into POMDP...
2024-09-03 12:00:37,706 - pomdp.py - constructed quotient MDP having 52921 states and 4228227 actions.
2024-09-03 12:00:48,434 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 12:00:48,470 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 12:00:48,470 - storm_pomdp_control.py - Storm already terminated.

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

2024-09-03 12:00:49,435 - synthesizer_ar_storm.py - Terminating controller synthesis
--------------------
Synthesis summary:
optimality objective: R{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 0.0 s
number of holes: 39421, family size: 1e46933, quotient: 52921 states / 4228227 actions
explored: 0 %

optimum: 17.0
--------------------
2024-09-03 12:00:49,445 - synthesizer_pomdp.py - Assignment is None
2024-09-03 12:00:49,445 - storm_pomdp_control.py - Storm POMDP analysis completed
2024-09-03 12:00:49,467 - synthesizer_rl.py - RL Environment initialized
2024-09-03 12:00:49,581 - ppo_with_qvalues_fsc.py - Agent initialized
2024-09-03 12:00:49,592 - ppo_with_qvalues_fsc.py - Replay buffer initialized
2024-09-03 12:00:50,528 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:50,986 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:51,377 - father_agent.py - Training agent
2024-09-03 12:00:51,620 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:52,684 - father_agent.py - Step: 0, Training loss: 0.15059205889701843
2024-09-03 12:00:54,815 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:55,084 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:55,230 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:56,165 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:56,469 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:56,549 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:56,789 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:57,341 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:57,708 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:57,869 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:58,255 - environment_wrapper.py - Goal reached!
2024-09-03 12:00:59,652 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:00,000 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:00,104 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:00,914 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:01,306 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:01,422 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:01,978 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:02,116 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:03,003 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:03,846 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:04,136 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:04,494 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:04,701 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:04,900 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:04,981 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:05,283 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:05,368 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:05,590 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:06,652 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:08,251 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:08,292 - father_agent.py - Average Return = -4027.199951171875
2024-09-03 12:01:08,292 - father_agent.py - Average Virtual Goal Value = 387.5
2024-09-03 12:01:08,292 - father_agent.py - Goal Reach Probability = 0.775
2024-09-03 12:01:08,892 - father_agent.py - Step: 10, Training loss: 0.1112651526927948
2024-09-03 12:01:08,977 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:09,490 - father_agent.py - Step: 20, Training loss: 0.4927155375480652
2024-09-03 12:01:10,080 - father_agent.py - Step: 30, Training loss: 0.3622278571128845
2024-09-03 12:01:10,669 - father_agent.py - Step: 40, Training loss: 0.29548534750938416
2024-09-03 12:01:11,255 - father_agent.py - Step: 50, Training loss: 0.21630792319774628
2024-09-03 12:01:11,843 - father_agent.py - Step: 60, Training loss: 0.46570250391960144
2024-09-03 12:01:12,428 - father_agent.py - Step: 70, Training loss: 0.526235818862915
2024-09-03 12:01:13,015 - father_agent.py - Step: 80, Training loss: 0.5283708572387695
2024-09-03 12:01:13,598 - father_agent.py - Step: 90, Training loss: 0.27000027894973755
2024-09-03 12:01:14,183 - father_agent.py - Step: 100, Training loss: 0.40131819248199463
2024-09-03 12:01:16,357 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:18,977 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:20,390 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:20,887 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:21,089 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:22,773 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:23,999 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:26,453 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:27,445 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:29,075 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:32,674 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:34,326 - father_agent.py - Average Return = -4313.27490234375
2024-09-03 12:01:34,327 - father_agent.py - Average Virtual Goal Value = 137.5
2024-09-03 12:01:34,327 - father_agent.py - Goal Reach Probability = 0.275
2024-09-03 12:01:34,685 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:34,915 - father_agent.py - Step: 110, Training loss: 0.3004547953605652
2024-09-03 12:01:35,502 - father_agent.py - Step: 120, Training loss: 0.2090812474489212
2024-09-03 12:01:35,752 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:36,088 - father_agent.py - Step: 130, Training loss: 0.15095768868923187
2024-09-03 12:01:36,674 - father_agent.py - Step: 140, Training loss: 0.35324230790138245
2024-09-03 12:01:37,260 - father_agent.py - Step: 150, Training loss: 0.2753799855709076
2024-09-03 12:01:37,839 - father_agent.py - Step: 160, Training loss: 0.3845615088939667
2024-09-03 12:01:37,884 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:38,390 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:38,447 - father_agent.py - Step: 170, Training loss: 0.39974939823150635
2024-09-03 12:01:39,034 - father_agent.py - Step: 180, Training loss: 0.2654169797897339
2024-09-03 12:01:39,430 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:39,626 - father_agent.py - Step: 190, Training loss: 0.10882721096277237
2024-09-03 12:01:40,214 - father_agent.py - Step: 200, Training loss: 0.2709954082965851
2024-09-03 12:01:43,114 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:45,089 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:45,153 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:46,733 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:52,045 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:55,096 - environment_wrapper.py - Goal reached!
2024-09-03 12:01:58,993 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:00,430 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:00,997 - father_agent.py - Average Return = -4027.175048828125
2024-09-03 12:02:00,997 - father_agent.py - Average Virtual Goal Value = 100.0
2024-09-03 12:02:00,997 - father_agent.py - Goal Reach Probability = 0.2
2024-09-03 12:02:01,317 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:01,592 - father_agent.py - Step: 210, Training loss: 0.22069354355335236
2024-09-03 12:02:02,184 - father_agent.py - Step: 220, Training loss: 0.7898802757263184
2024-09-03 12:02:02,794 - father_agent.py - Step: 230, Training loss: 0.18038685619831085
2024-09-03 12:02:03,378 - father_agent.py - Step: 240, Training loss: 0.49899277091026306
2024-09-03 12:02:03,966 - father_agent.py - Step: 250, Training loss: 1.1790260076522827
2024-09-03 12:02:04,555 - father_agent.py - Step: 260, Training loss: 0.2154586911201477
2024-09-03 12:02:05,140 - father_agent.py - Step: 270, Training loss: 0.20718711614608765
2024-09-03 12:02:05,725 - father_agent.py - Step: 280, Training loss: 0.38249465823173523
2024-09-03 12:02:05,790 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:06,314 - father_agent.py - Step: 290, Training loss: 0.18630261719226837
2024-09-03 12:02:06,576 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:06,899 - father_agent.py - Step: 300, Training loss: 0.5670539736747742
2024-09-03 12:02:09,352 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:12,206 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:13,681 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:16,999 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:22,150 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:25,641 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:25,811 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:28,714 - father_agent.py - Average Return = -4731.0498046875
2024-09-03 12:02:28,714 - father_agent.py - Average Virtual Goal Value = 87.5
2024-09-03 12:02:28,714 - father_agent.py - Goal Reach Probability = 0.175
2024-09-03 12:02:29,302 - father_agent.py - Step: 310, Training loss: 0.39953839778900146
2024-09-03 12:02:29,889 - father_agent.py - Step: 320, Training loss: 0.34820541739463806
2024-09-03 12:02:30,472 - father_agent.py - Step: 330, Training loss: 0.18228721618652344
2024-09-03 12:02:31,060 - father_agent.py - Step: 340, Training loss: 0.3559609055519104
2024-09-03 12:02:31,653 - father_agent.py - Step: 350, Training loss: 0.45890891551971436
2024-09-03 12:02:31,696 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:32,246 - father_agent.py - Step: 360, Training loss: 0.36492785811424255
2024-09-03 12:02:32,833 - father_agent.py - Step: 370, Training loss: 0.1068059578537941
2024-09-03 12:02:33,422 - father_agent.py - Step: 380, Training loss: 0.2151879370212555
2024-09-03 12:02:34,012 - father_agent.py - Step: 390, Training loss: 0.2948386073112488
2024-09-03 12:02:34,600 - father_agent.py - Step: 400, Training loss: 0.17055872082710266
2024-09-03 12:02:35,791 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:41,844 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:45,509 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:46,890 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:47,847 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:50,964 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:52,341 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:55,311 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:55,313 - father_agent.py - Average Return = -4000.199951171875
2024-09-03 12:02:55,313 - father_agent.py - Average Virtual Goal Value = 100.0
2024-09-03 12:02:55,313 - father_agent.py - Goal Reach Probability = 0.2
2024-09-03 12:02:55,903 - father_agent.py - Step: 410, Training loss: 0.3876153230667114
2024-09-03 12:02:56,495 - father_agent.py - Step: 420, Training loss: 0.43813568353652954
2024-09-03 12:02:56,616 - environment_wrapper.py - Goal reached!
2024-09-03 12:02:57,085 - father_agent.py - Step: 430, Training loss: 0.4925662875175476
2024-09-03 12:02:57,666 - father_agent.py - Step: 440, Training loss: 0.2657780945301056
2024-09-03 12:02:58,253 - father_agent.py - Step: 450, Training loss: 0.10587149113416672
2024-09-03 12:02:58,844 - father_agent.py - Step: 460, Training loss: 0.0707101821899414
2024-09-03 12:02:59,430 - father_agent.py - Step: 470, Training loss: 0.16160832345485687
2024-09-03 12:03:00,019 - father_agent.py - Step: 480, Training loss: 0.11232917010784149
2024-09-03 12:03:00,607 - father_agent.py - Step: 490, Training loss: 0.17646877467632294
2024-09-03 12:03:01,195 - father_agent.py - Step: 500, Training loss: 0.1432894915342331
2024-09-03 12:03:01,690 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:02,563 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:03,033 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:04,839 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:05,155 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:08,872 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:09,938 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:10,699 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:12,291 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:12,543 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:12,691 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:15,840 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:16,074 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:16,154 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:16,836 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:17,032 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:19,334 - father_agent.py - Average Return = -4079.175048828125
2024-09-03 12:03:19,334 - father_agent.py - Average Virtual Goal Value = 200.0
2024-09-03 12:03:19,334 - father_agent.py - Goal Reach Probability = 0.4
2024-09-03 12:03:19,917 - father_agent.py - Step: 510, Training loss: 0.07355868816375732
2024-09-03 12:03:20,496 - father_agent.py - Step: 520, Training loss: 0.11706012487411499
2024-09-03 12:03:21,080 - father_agent.py - Step: 530, Training loss: 0.1834249049425125
2024-09-03 12:03:21,666 - father_agent.py - Step: 540, Training loss: 0.1593337059020996
2024-09-03 12:03:22,105 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:22,259 - father_agent.py - Step: 550, Training loss: 0.09899015724658966
2024-09-03 12:03:22,844 - father_agent.py - Step: 560, Training loss: 0.06378749012947083
2024-09-03 12:03:23,227 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:23,435 - father_agent.py - Step: 570, Training loss: 0.21882474422454834
2024-09-03 12:03:24,019 - father_agent.py - Step: 580, Training loss: 0.2842636704444885
2024-09-03 12:03:24,604 - father_agent.py - Step: 590, Training loss: 0.2975757420063019
2024-09-03 12:03:25,190 - father_agent.py - Step: 600, Training loss: 0.45816540718078613
2024-09-03 12:03:26,069 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:26,162 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:27,423 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:32,500 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:34,324 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:35,151 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:39,729 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:40,705 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:45,628 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:45,630 - father_agent.py - Average Return = -2810.949951171875
2024-09-03 12:03:45,637 - father_agent.py - Average Virtual Goal Value = 112.5
2024-09-03 12:03:45,637 - father_agent.py - Goal Reach Probability = 0.225
2024-09-03 12:03:46,232 - father_agent.py - Step: 610, Training loss: 0.19317874312400818
2024-09-03 12:03:46,825 - father_agent.py - Step: 620, Training loss: 0.3152309060096741
2024-09-03 12:03:47,052 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:47,418 - father_agent.py - Step: 630, Training loss: 0.2778569161891937
2024-09-03 12:03:48,004 - father_agent.py - Step: 640, Training loss: 0.3203214108943939
2024-09-03 12:03:48,590 - father_agent.py - Step: 650, Training loss: 0.13527369499206543
2024-09-03 12:03:49,172 - father_agent.py - Step: 660, Training loss: 0.07538895308971405
2024-09-03 12:03:49,758 - father_agent.py - Step: 670, Training loss: 0.2518278658390045
2024-09-03 12:03:50,352 - father_agent.py - Step: 680, Training loss: 0.15365390479564667
2024-09-03 12:03:50,390 - environment_wrapper.py - Goal reached!
2024-09-03 12:03:50,945 - father_agent.py - Step: 690, Training loss: 0.3457145392894745
2024-09-03 12:03:51,531 - father_agent.py - Step: 700, Training loss: 0.08671453595161438
2024-09-03 12:03:53,290 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:01,565 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:05,733 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:11,275 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:13,559 - father_agent.py - Average Return = -3174.02490234375
2024-09-03 12:04:13,559 - father_agent.py - Average Virtual Goal Value = 50.0
2024-09-03 12:04:13,559 - father_agent.py - Goal Reach Probability = 0.1
2024-09-03 12:04:14,148 - father_agent.py - Step: 710, Training loss: 0.29776662588119507
2024-09-03 12:04:14,735 - father_agent.py - Step: 720, Training loss: 0.17992666363716125
2024-09-03 12:04:14,920 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:15,326 - father_agent.py - Step: 730, Training loss: 0.08914299309253693
2024-09-03 12:04:15,911 - father_agent.py - Step: 740, Training loss: 0.13841398060321808
2024-09-03 12:04:16,495 - father_agent.py - Step: 750, Training loss: 0.09515577554702759
2024-09-03 12:04:17,080 - father_agent.py - Step: 760, Training loss: 0.17562216520309448
2024-09-03 12:04:17,664 - father_agent.py - Step: 770, Training loss: 0.1476748287677765
2024-09-03 12:04:18,251 - father_agent.py - Step: 780, Training loss: 0.14149066805839539
2024-09-03 12:04:18,838 - father_agent.py - Step: 790, Training loss: 0.05306360125541687
2024-09-03 12:04:19,416 - father_agent.py - Step: 800, Training loss: 0.09196195006370544
2024-09-03 12:04:27,738 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:27,879 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:27,940 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:31,074 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:38,252 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:40,524 - father_agent.py - Average Return = -2697.47509765625
2024-09-03 12:04:40,524 - father_agent.py - Average Virtual Goal Value = 62.5
2024-09-03 12:04:40,524 - father_agent.py - Goal Reach Probability = 0.125
2024-09-03 12:04:41,103 - father_agent.py - Step: 810, Training loss: 0.19873355329036713
2024-09-03 12:04:41,681 - father_agent.py - Step: 820, Training loss: 0.1470741629600525
2024-09-03 12:04:42,265 - father_agent.py - Step: 830, Training loss: 0.08968513458967209
2024-09-03 12:04:42,846 - father_agent.py - Step: 840, Training loss: 0.14088702201843262
2024-09-03 12:04:43,438 - father_agent.py - Step: 850, Training loss: 0.12172789871692657
2024-09-03 12:04:44,022 - father_agent.py - Step: 860, Training loss: 0.1740715503692627
2024-09-03 12:04:44,606 - father_agent.py - Step: 870, Training loss: 0.13874848186969757
2024-09-03 12:04:45,194 - father_agent.py - Step: 880, Training loss: 0.15656280517578125
2024-09-03 12:04:45,779 - father_agent.py - Step: 890, Training loss: 0.12831562757492065
2024-09-03 12:04:46,367 - father_agent.py - Step: 900, Training loss: 0.1383972018957138
2024-09-03 12:04:47,791 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:48,523 - environment_wrapper.py - Goal reached!
2024-09-03 12:04:48,642 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:06,281 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:08,011 - father_agent.py - Average Return = -2617.64990234375
2024-09-03 12:05:08,011 - father_agent.py - Average Virtual Goal Value = 50.0
2024-09-03 12:05:08,011 - father_agent.py - Goal Reach Probability = 0.1
2024-09-03 12:05:08,327 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:08,601 - father_agent.py - Step: 910, Training loss: 0.14446143805980682
2024-09-03 12:05:09,185 - father_agent.py - Step: 920, Training loss: 0.10483512282371521
2024-09-03 12:05:09,771 - father_agent.py - Step: 930, Training loss: 0.13450324535369873
2024-09-03 12:05:10,357 - father_agent.py - Step: 940, Training loss: 0.11133133620023727
2024-09-03 12:05:10,945 - father_agent.py - Step: 950, Training loss: 0.16486166417598724
2024-09-03 12:05:11,534 - father_agent.py - Step: 960, Training loss: 0.1499570608139038
2024-09-03 12:05:12,129 - father_agent.py - Step: 970, Training loss: 0.0790422335267067
2024-09-03 12:05:12,718 - father_agent.py - Step: 980, Training loss: 0.06802302598953247
2024-09-03 12:05:13,307 - father_agent.py - Step: 990, Training loss: 0.08390040695667267
2024-09-03 12:05:13,895 - father_agent.py - Step: 1000, Training loss: 0.15004678070545197
2024-09-03 12:05:19,243 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:29,533 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:36,430 - father_agent.py - Average Return = -2899.074951171875
2024-09-03 12:05:36,430 - father_agent.py - Average Virtual Goal Value = 25.0
2024-09-03 12:05:36,430 - father_agent.py - Goal Reach Probability = 0.05
2024-09-03 12:05:37,018 - father_agent.py - Step: 1010, Training loss: 0.10783861577510834
2024-09-03 12:05:37,609 - father_agent.py - Step: 1020, Training loss: 0.09575851261615753
2024-09-03 12:05:38,205 - father_agent.py - Step: 1030, Training loss: 0.06279413402080536
2024-09-03 12:05:38,790 - father_agent.py - Step: 1040, Training loss: 0.2125592827796936
2024-09-03 12:05:39,385 - father_agent.py - Step: 1050, Training loss: 0.2272336781024933
2024-09-03 12:05:39,974 - father_agent.py - Step: 1060, Training loss: 0.39444413781166077
2024-09-03 12:05:40,369 - environment_wrapper.py - Goal reached!
2024-09-03 12:05:40,565 - father_agent.py - Step: 1070, Training loss: 0.1368904560804367
2024-09-03 12:05:41,153 - father_agent.py - Step: 1080, Training loss: 0.0873691737651825
2024-09-03 12:05:41,735 - father_agent.py - Step: 1090, Training loss: 0.19645003974437714
2024-09-03 12:05:42,320 - father_agent.py - Step: 1100, Training loss: 0.17262399196624756
2024-09-03 12:05:47,268 - environment_wrapper.py - Goal reached!
2024-09-03 12:06:02,124 - environment_wrapper.py - Goal reached!
2024-09-03 12:06:03,089 - environment_wrapper.py - Goal reached!
2024-09-03 12:06:04,824 - father_agent.py - Average Return = -2054.449951171875
2024-09-03 12:06:04,824 - father_agent.py - Average Virtual Goal Value = 37.5
2024-09-03 12:06:04,824 - father_agent.py - Goal Reach Probability = 0.075
2024-09-03 12:06:05,412 - father_agent.py - Step: 1110, Training loss: 0.12862159311771393
2024-09-03 12:06:06,001 - father_agent.py - Step: 1120, Training loss: 0.40378865599632263
2024-09-03 12:06:06,589 - father_agent.py - Step: 1130, Training loss: 0.16736535727977753
2024-09-03 12:06:07,176 - father_agent.py - Step: 1140, Training loss: 0.22106274962425232
2024-09-03 12:06:07,762 - father_agent.py - Step: 1150, Training loss: 0.34342896938323975
2024-09-03 12:06:08,347 - father_agent.py - Step: 1160, Training loss: 0.16785593330860138
2024-09-03 12:06:08,928 - father_agent.py - Step: 1170, Training loss: 0.12498416006565094
2024-09-03 12:06:09,508 - father_agent.py - Step: 1180, Training loss: 0.2319914847612381
2024-09-03 12:06:10,091 - father_agent.py - Step: 1190, Training loss: 0.10772991180419922
2024-09-03 12:06:10,674 - father_agent.py - Step: 1200, Training loss: 0.1882382333278656
2024-09-03 12:06:23,593 - environment_wrapper.py - Goal reached!
2024-09-03 12:06:33,575 - father_agent.py - Average Return = -2325.14990234375
2024-09-03 12:06:33,575 - father_agent.py - Average Virtual Goal Value = 12.5
2024-09-03 12:06:33,575 - father_agent.py - Goal Reach Probability = 0.025
2024-09-03 12:06:34,166 - father_agent.py - Step: 1210, Training loss: 0.16810496151447296
2024-09-03 12:06:34,750 - father_agent.py - Step: 1220, Training loss: 0.3060345947742462
2024-09-03 12:06:35,362 - father_agent.py - Step: 1230, Training loss: 0.16488692164421082
2024-09-03 12:06:36,007 - father_agent.py - Step: 1240, Training loss: 0.11066490411758423
2024-09-03 12:06:36,606 - father_agent.py - Step: 1250, Training loss: 0.1502932608127594
2024-09-03 12:06:37,200 - father_agent.py - Step: 1260, Training loss: 0.14615130424499512
2024-09-03 12:06:37,916 - father_agent.py - Step: 1270, Training loss: 0.11904815584421158
2024-09-03 12:06:38,637 - father_agent.py - Step: 1280, Training loss: 0.10489824414253235
2024-09-03 12:06:39,272 - father_agent.py - Step: 1290, Training loss: 0.16323387622833252
2024-09-03 12:06:39,872 - father_agent.py - Step: 1300, Training loss: 0.2172209769487381
2024-09-03 12:06:47,746 - environment_wrapper.py - Goal reached!
2024-09-03 12:06:48,575 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:03,523 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:03,525 - father_agent.py - Average Return = -2255.77490234375
2024-09-03 12:07:03,525 - father_agent.py - Average Virtual Goal Value = 37.5
2024-09-03 12:07:03,525 - father_agent.py - Goal Reach Probability = 0.075
2024-09-03 12:07:04,134 - father_agent.py - Step: 1310, Training loss: 0.15246674418449402
2024-09-03 12:07:04,839 - father_agent.py - Step: 1320, Training loss: 0.09318624436855316
2024-09-03 12:07:05,470 - father_agent.py - Step: 1330, Training loss: 0.3420974016189575
2024-09-03 12:07:06,118 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:06,144 - father_agent.py - Step: 1340, Training loss: 0.11502190679311752
2024-09-03 12:07:06,772 - father_agent.py - Step: 1350, Training loss: 0.19699813425540924
2024-09-03 12:07:07,402 - father_agent.py - Step: 1360, Training loss: 0.12318670004606247
2024-09-03 12:07:08,104 - father_agent.py - Step: 1370, Training loss: 0.16145765781402588
2024-09-03 12:07:08,747 - father_agent.py - Step: 1380, Training loss: 0.3463006913661957
2024-09-03 12:07:09,393 - father_agent.py - Step: 1390, Training loss: 0.15648998320102692
2024-09-03 12:07:10,189 - father_agent.py - Step: 1400, Training loss: 0.07199893891811371
2024-09-03 12:07:13,091 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:32,877 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:33,176 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:33,759 - father_agent.py - Average Return = -1892.949951171875
2024-09-03 12:07:33,759 - father_agent.py - Average Virtual Goal Value = 37.5
2024-09-03 12:07:33,759 - father_agent.py - Goal Reach Probability = 0.075
2024-09-03 12:07:34,353 - father_agent.py - Step: 1410, Training loss: 0.09806443750858307
2024-09-03 12:07:34,954 - father_agent.py - Step: 1420, Training loss: 0.1080189123749733
2024-09-03 12:07:35,556 - father_agent.py - Step: 1430, Training loss: 0.16980762779712677
2024-09-03 12:07:36,246 - father_agent.py - Step: 1440, Training loss: 0.06327543407678604
2024-09-03 12:07:36,839 - father_agent.py - Step: 1450, Training loss: 0.1305137574672699
2024-09-03 12:07:37,429 - father_agent.py - Step: 1460, Training loss: 0.23742589354515076
2024-09-03 12:07:38,120 - father_agent.py - Step: 1470, Training loss: 0.20358121395111084
2024-09-03 12:07:38,721 - father_agent.py - Step: 1480, Training loss: 0.16431641578674316
2024-09-03 12:07:39,315 - father_agent.py - Step: 1490, Training loss: 0.08058740198612213
2024-09-03 12:07:39,914 - father_agent.py - Step: 1500, Training loss: 0.11679582297801971
2024-09-03 12:07:47,978 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:52,164 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:53,690 - environment_wrapper.py - Goal reached!
2024-09-03 12:07:59,898 - environment_wrapper.py - Goal reached!
2024-09-03 12:08:03,445 - father_agent.py - Average Return = -2060.050048828125
2024-09-03 12:08:03,445 - father_agent.py - Average Virtual Goal Value = 50.0
2024-09-03 12:08:03,445 - father_agent.py - Goal Reach Probability = 0.1
2024-09-03 12:08:04,142 - father_agent.py - Step: 1510, Training loss: 0.13803347945213318
2024-09-03 12:08:04,759 - father_agent.py - Step: 1520, Training loss: 0.1267506629228592
2024-09-03 12:08:05,360 - father_agent.py - Step: 1530, Training loss: 0.10626621544361115
2024-09-03 12:08:06,019 - father_agent.py - Step: 1540, Training loss: 0.0630781501531601
2024-09-03 12:08:06,643 - father_agent.py - Step: 1550, Training loss: 0.22115710377693176
2024-09-03 12:08:07,244 - father_agent.py - Step: 1560, Training loss: 0.010737679898738861
2024-09-03 12:08:07,849 - father_agent.py - Step: 1570, Training loss: 0.11404448002576828
2024-09-03 12:08:08,440 - father_agent.py - Step: 1580, Training loss: 0.1727822870016098
2024-09-03 12:08:09,045 - father_agent.py - Step: 1590, Training loss: 0.24448512494564056
2024-09-03 12:08:09,642 - father_agent.py - Step: 1600, Training loss: 0.14588835835456848
2024-09-03 12:08:13,081 - environment_wrapper.py - Goal reached!
2024-09-03 12:08:33,613 - father_agent.py - Average Return = -1541.0999755859375
2024-09-03 12:08:33,613 - father_agent.py - Average Virtual Goal Value = 12.5
2024-09-03 12:08:33,613 - father_agent.py - Goal Reach Probability = 0.025
2024-09-03 12:08:34,209 - father_agent.py - Step: 1610, Training loss: 0.0657687783241272
2024-09-03 12:08:34,807 - father_agent.py - Step: 1620, Training loss: 0.15999144315719604
2024-09-03 12:08:35,403 - father_agent.py - Step: 1630, Training loss: 0.1822493076324463
2024-09-03 12:08:36,099 - father_agent.py - Step: 1640, Training loss: 0.25212961435317993
2024-09-03 12:08:36,714 - father_agent.py - Step: 1650, Training loss: 0.11152543872594833
2024-09-03 12:08:37,319 - father_agent.py - Step: 1660, Training loss: 0.1383742392063141
2024-09-03 12:08:37,913 - father_agent.py - Step: 1670, Training loss: 0.1520983874797821
2024-09-03 12:08:38,510 - father_agent.py - Step: 1680, Training loss: -0.08716318011283875
2024-09-03 12:08:39,109 - father_agent.py - Step: 1690, Training loss: 0.13508805632591248
2024-09-03 12:08:39,707 - father_agent.py - Step: 1700, Training loss: 0.22352921962738037
2024-09-03 12:08:56,717 - environment_wrapper.py - Goal reached!
2024-09-03 12:08:59,398 - environment_wrapper.py - Goal reached!
2024-09-03 12:09:00,916 - environment_wrapper.py - Goal reached!
2024-09-03 12:09:03,272 - father_agent.py - Average Return = -1458.699951171875
2024-09-03 12:09:03,272 - father_agent.py - Average Virtual Goal Value = 37.5
2024-09-03 12:09:03,272 - father_agent.py - Goal Reach Probability = 0.075
2024-09-03 12:09:03,916 - father_agent.py - Step: 1710, Training loss: 0.11554473638534546
2024-09-03 12:09:04,587 - father_agent.py - Step: 1720, Training loss: 0.09601398557424545
2024-09-03 12:09:05,185 - father_agent.py - Step: 1730, Training loss: 0.014947891235351562
2024-09-03 12:09:05,784 - father_agent.py - Step: 1740, Training loss: 0.5855786800384521
2024-09-03 12:09:06,474 - father_agent.py - Step: 1750, Training loss: 0.19981902837753296
2024-09-03 12:09:07,069 - father_agent.py - Step: 1760, Training loss: 0.15040695667266846
2024-09-03 12:09:07,663 - father_agent.py - Step: 1770, Training loss: 0.055924899876117706
2024-09-03 12:09:08,356 - father_agent.py - Step: 1780, Training loss: 0.04865413159132004
2024-09-03 12:09:08,960 - father_agent.py - Step: 1790, Training loss: 0.05437379702925682
2024-09-03 12:09:09,560 - father_agent.py - Step: 1800, Training loss: 0.10172613710165024
2024-09-03 12:09:33,980 - father_agent.py - Average Return = -1235.824951171875
2024-09-03 12:09:33,980 - father_agent.py - Average Virtual Goal Value = 0.0
2024-09-03 12:09:33,980 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 12:09:34,578 - father_agent.py - Step: 1810, Training loss: -0.000566285103559494
2024-09-03 12:09:35,177 - father_agent.py - Step: 1820, Training loss: 0.12614789605140686
2024-09-03 12:09:35,773 - father_agent.py - Step: 1830, Training loss: 0.03732307627797127
2024-09-03 12:09:36,460 - father_agent.py - Step: 1840, Training loss: 0.06307041645050049
2024-09-03 12:09:37,067 - father_agent.py - Step: 1850, Training loss: 0.09738221019506454
2024-09-03 12:09:37,660 - father_agent.py - Step: 1860, Training loss: 0.08308476209640503
2024-09-03 12:09:38,269 - father_agent.py - Step: 1870, Training loss: 0.1367158591747284
2024-09-03 12:09:38,870 - father_agent.py - Step: 1880, Training loss: 0.14908912777900696
2024-09-03 12:09:39,467 - father_agent.py - Step: 1890, Training loss: 0.11606749892234802
2024-09-03 12:09:40,167 - father_agent.py - Step: 1900, Training loss: 0.09155353158712387
2024-09-03 12:09:48,516 - environment_wrapper.py - Goal reached!
2024-09-03 12:10:04,382 - father_agent.py - Average Return = -1491.4749755859375
2024-09-03 12:10:04,382 - father_agent.py - Average Virtual Goal Value = 12.5
2024-09-03 12:10:04,382 - father_agent.py - Goal Reach Probability = 0.025
2024-09-03 12:10:04,969 - father_agent.py - Step: 1910, Training loss: 0.02343040332198143
2024-09-03 12:10:05,573 - father_agent.py - Step: 1920, Training loss: 0.06750522553920746
2024-09-03 12:10:06,270 - father_agent.py - Step: 1930, Training loss: 0.12570875883102417
2024-09-03 12:10:06,672 - environment_wrapper.py - Goal reached!
2024-09-03 12:10:06,871 - father_agent.py - Step: 1940, Training loss: 0.12051045149564743
2024-09-03 12:10:07,477 - father_agent.py - Step: 1950, Training loss: 0.07834877073764801
2024-09-03 12:10:08,172 - father_agent.py - Step: 1960, Training loss: 0.11597731709480286
2024-09-03 12:10:08,770 - father_agent.py - Step: 1970, Training loss: 0.10006985068321228
2024-09-03 12:10:09,369 - father_agent.py - Step: 1980, Training loss: 0.09368906915187836
2024-09-03 12:10:09,968 - father_agent.py - Step: 1990, Training loss: 0.0997323989868164
2024-09-03 12:10:44,319 - environment_wrapper.py - Goal reached!
2024-09-03 12:10:45,008 - environment_wrapper.py - Goal reached!
2024-09-03 12:10:58,450 - father_agent.py - Average Return = -1343.7750244140625
2024-09-03 12:10:58,450 - father_agent.py - Average Virtual Goal Value = 12.5
2024-09-03 12:10:58,450 - father_agent.py - Goal Reach Probability = 0.025

------------------------------------

PAYNT results: 
17.0
controller size: 1962

Storm results: 
17.0
controller size: 1522

------------------------------------

