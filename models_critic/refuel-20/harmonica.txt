2024-09-03 01:37:29,461 - cli.py - This is Paynt version 0.1.0.
2024-09-03 01:37:29,461 - sketch.py - loading sketch from models_critic/refuel-20/sketch.templ ...
2024-09-03 01:37:29,461 - sketch.py - assuming sketch in PRISM format...
2024-09-03 01:37:29,465 - prism_parser.py - PRISM model type: POMDP
2024-09-03 01:37:29,465 - prism_parser.py - loading properties from models_critic/refuel-20/sketch.props ...
2024-09-03 01:37:29,466 - prism_parser.py - found the following specification: optimality: Pmax=? ["notbad" U "goal"] 
2024-09-03 01:37:29,519 - sketch.py - sketch parsing OK
2024-09-03 01:37:29,526 - sketch.py - constructed explicit quotient having 6834 states and 24763 actions
2024-09-03 01:37:29,526 - property.py - converting until formula to eventually...
2024-09-03 01:37:29,526 - sketch.py - found the following specification optimality: Pmax=? [F "goal"] 
2024-09-03 01:37:29,532 - pomdp.py - constructed POMDP having 174 observations.
2024-09-03 01:37:29,535 - pomdp.py - unfolding 1-FSC template into POMDP...
2024-09-03 01:37:29,548 - pomdp.py - constructed quotient MDP having 6834 states and 24763 actions.
2024-09-03 01:37:30,180 - tpu_cluster_resolver.py - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-09-03 01:37:30,293 - __init__.py - Creating converter from 7 to 5
2024-09-03 01:37:30,294 - __init__.py - Creating converter from 5 to 7
2024-09-03 01:37:30,294 - __init__.py - Creating converter from 7 to 5
2024-09-03 01:37:30,294 - __init__.py - Creating converter from 5 to 7
2024-09-03 01:37:31,010 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-09-03 01:37:31,010 - synthesizer_pomdp.py - Storm settings: iterative - (600, 30, 10), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False
2024-09-03 01:37:31,015 - synthesizer_pomdp.py - Timeout for PAYNT started
-----------PAYNT-----------                     
Value = 0.0 | Time elapsed = 0.6s | FSC size = 348

> progress 0.0%, elapsed 3 s, estimated 809064804091 s (25655 years), iters = {MDP: 467}, opt = 0.0
-----------PAYNT-----------                     
Value = 0.0008297651344919832 | Time elapsed = 4.6s | FSC size = 348

> progress 0.0%, elapsed 6 s, estimated 1620100057415 s (51373 years), iters = {MDP: 1095}, opt = 0.001
> progress 0.0%, elapsed 9 s, estimated 2430674255772 s (77076 years), iters = {MDP: 1747}, opt = 0.001
> progress 0.0%, elapsed 12 s, estimated 3240234274011 s (102747 years), iters = {MDP: 2372}, opt = 0.001
> progress 0.0%, elapsed 15 s, estimated 4048100999857 s (128364 years), iters = {MDP: 2958}, opt = 0.001
> progress 0.0%, elapsed 18 s, estimated 4859575103283 s (154096 years), iters = {MDP: 3564}, opt = 0.001
> progress 0.0%, elapsed 21 s, estimated 5668844757561 s (179757 years), iters = {MDP: 4191}, opt = 0.001
> progress 0.0%, elapsed 24 s, estimated 6476715445521 s (205375 years), iters = {MDP: 4803}, opt = 0.001
> progress 0.0%, elapsed 27 s, estimated 7286905831170 s (231066 years), iters = {MDP: 5453}, opt = 0.001
2024-09-03 01:38:01,156 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:38:01,158 - storm_pomdp_control.py - Interactive Storm started
2024-09-03 01:38:01,158 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-09-03 01:38:12,169 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.13441287769717072 | Time elapsed = 49.2s | FSC size = 1153


------------------------------------

PAYNT results: 
0.0008297651344919832
controller size: 348

Storm results: 
0.13441287769717072
controller size: 1153

------------------------------------

2024-09-03 01:38:20,256 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:38:21,178 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:38:21,179 - synthesizer_ar_storm.py - Additional memory needed
2024-09-03 01:38:21,188 - synthesizer.py - double-checking specification satisfiability:  : 0.0008297651344919832
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 30.15 s
number of holes: 104, family size: 1e48, quotient: 6834 states / 24763 actions
explored: 0 %
MDP stats: avg MDP size: 2511, iterations: 6094

optimum: 0.00083
--------------------
2024-09-03 01:38:22,010 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-09-03 01:38:22,011 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-09-03 01:38:22,016 - pomdp.py - constructed quotient MDP having 6986 states and 25667 actions.
2024-09-03 01:38:22,029 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e50 to 32
-----------PAYNT-----------                     
Value = 0.11084902583077773 | Time elapsed = 51.0s | FSC size = 350

-----------PAYNT-----------                     
Value = 0.15541658291131832 | Time elapsed = 51.0s | FSC size = 350

-----------PAYNT-----------                     
Value = 0.19246617384346698 | Time elapsed = 51.0s | FSC size = 350

2024-09-03 01:38:22,064 - synthesizer_ar_storm.py - Main family synthesis done
2024-09-03 01:38:22,064 - synthesizer_ar_storm.py - Subfamilies buffer contains: 21 families
> progress 0.0%, elapsed 3 s, estimated 2074412641151 s (65779 years), iters = {MDP: 838}, opt = 0.192
> progress 0.0%, elapsed 6 s, estimated 3141180701721 s (99606 years), iters = {MDP: 1736}, opt = 0.192
> progress 0.0%, elapsed 9 s, estimated 3924582688147 s (124447 years), iters = {MDP: 2559}, opt = 0.192
> progress 0.0%, elapsed 12 s, estimated 2684287510562 s (85118 years), iters = {MDP: 3380}, opt = 0.192
> progress 0.0%, elapsed 15 s, estimated 2936124091657 s (93103 years), iters = {MDP: 4243}, opt = 0.192
> progress 0.0%, elapsed 18 s, estimated 3166692110455 s (100415 years), iters = {MDP: 5019}, opt = 0.192
> progress 0.0%, elapsed 21 s, estimated 3053495196061 s (96825 years), iters = {MDP: 5840}, opt = 0.192
-----------PAYNT-----------                     
Value = 0.20083683265429667 | Time elapsed = 72.3s | FSC size = 350

-----------PAYNT-----------                     
Value = 0.21353753026958866 | Time elapsed = 72.3s | FSC size = 350

> progress 0.0%, elapsed 24 s, estimated 2755853857733 s (87387 years), iters = {MDP: 6657}, opt = 0.214
> progress 0.0%, elapsed 27 s, estimated 2891761973195 s (91697 years), iters = {MDP: 7495}, opt = 0.214
2024-09-03 01:38:50,439 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:38:50,498 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:38:50,498 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:39:01,510 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.21712087220498325 | Time elapsed = 103.5s | FSC size = 1503


------------------------------------

PAYNT results: 
0.21353753026958866
controller size: 350

Storm results: 
0.21712087220498325
controller size: 1503

------------------------------------

2024-09-03 01:39:14,604 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:39:15,466 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:39:15,467 - synthesizer_ar_storm.py - Additional memory needed
2024-09-03 01:39:15,479 - synthesizer.py - double-checking specification satisfiability:  : 0.21353753026958866
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 28.41 s
number of holes: 108, family size: 1e50, quotient: 6986 states / 25667 actions
explored: 0 %
MDP stats: avg MDP size: 2831, iterations: 7835

optimum: 0.213538
--------------------
2024-09-03 01:39:17,134 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-09-03 01:39:17,136 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-09-03 01:39:17,143 - pomdp.py - constructed quotient MDP having 6988 states and 25711 actions.
2024-09-03 01:39:17,156 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e56 to 1e7
-----------PAYNT-----------                     
Value = 0.2147311758111899 | Time elapsed = 106.3s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.21586175219203438 | Time elapsed = 106.4s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2162544064059849 | Time elapsed = 106.4s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.21937242437574073 | Time elapsed = 106.4s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2201101595531282 | Time elapsed = 106.4s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.221262376996729 | Time elapsed = 106.7s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.22204842453489826 | Time elapsed = 106.7s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2224222502166059 | Time elapsed = 106.8s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.22518845179953212 | Time elapsed = 106.8s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.22558165813424438 | Time elapsed = 106.8s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2281242028807641 | Time elapsed = 107.1s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.22863471758236378 | Time elapsed = 107.1s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2325318064164771 | Time elapsed = 107.1s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2351895112847802 | Time elapsed = 107.1s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.23536650657922695 | Time elapsed = 107.1s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.23652159315352517 | Time elapsed = 107.2s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.23886903916262775 | Time elapsed = 107.2s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.23909777372538815 | Time elapsed = 107.7s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2406514524952468 | Time elapsed = 107.7s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2409403360665751 | Time elapsed = 107.7s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.24140329533614335 | Time elapsed = 107.8s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.24264671524680168 | Time elapsed = 107.8s | FSC size = 352

-----------PAYNT-----------                     
Value = 0.2436713977882082 | Time elapsed = 107.8s | FSC size = 352

> progress 0.0%, elapsed 3 s, estimated 22550312654433400534210432217778703765524625489920 s (715065723440937324078887705454512718217216 years), iters = {MDP: 1003}, opt = 0.244
2024-09-03 01:39:22,860 - synthesizer_ar_storm.py - Main family synthesis done
2024-09-03 01:39:22,860 - synthesizer_ar_storm.py - Subfamilies buffer contains: 106 families
> progress 0.0%, elapsed 6 s, estimated 20737849589530028680862431889679472633060448534528 s (657592896674595077840260336281243449556992 years), iters = {MDP: 2043}, opt = 0.244
> progress 0.0%, elapsed 9 s, estimated 22114675535848483465824106003372458481314196094976 s (701251761030203044819413739456352837697536 years), iters = {MDP: 3090}, opt = 0.244
> progress 0.0%, elapsed 12 s, estimated 18912606501341162328353684167499031476339617038336 s (599714818028321955640646879131502253178880 years), iters = {MDP: 4032}, opt = 0.244
> progress 0.0%, elapsed 15 s, estimated 17224038709793931983822855523369423247854996029440 s (546170684607874595842656945949237462433792 years), iters = {MDP: 5057}, opt = 0.244
> progress 0.0%, elapsed 18 s, estimated 11679118040032874769419135523620195398450134646784 s (370342403603274784720162345247741250109440 years), iters = {MDP: 6072}, opt = 0.244
> progress 0.0%, elapsed 21 s, estimated 8704202173507636602886773024050820890054908444672 s (276008440306558730141489129290242377908224 years), iters = {MDP: 7091}, opt = 0.244
> progress 0.0%, elapsed 24 s, estimated 7102538716938875249702781291465671187124782628864 s (225220025270765941368592429723612551839744 years), iters = {MDP: 8121}, opt = 0.244
> progress 0.0%, elapsed 27 s, estimated 4462752419519587421633495831801174617179834810368 s (141512950898008211295797020229471525928960 years), iters = {MDP: 9151}, opt = 0.244
2024-09-03 01:39:44,810 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:39:44,845 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:39:44,845 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:39:55,857 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.25671814046658126 | Time elapsed = 161.9s | FSC size = 1509


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.25671814046658126
controller size: 1509

------------------------------------

2024-09-03 01:40:12,953 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:40:13,842 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:40:13,842 - synthesizer_ar_storm.py - Additional memory needed
2024-09-03 01:40:13,846 - synthesizer.py - double-checking specification satisfiability:  : 0.2436713977882082
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 27.65 s
number of holes: 127, family size: 1e56, quotient: 6988 states / 25711 actions
explored: 0 %
MDP stats: avg MDP size: 2105, iterations: 9312

optimum: 0.243671
--------------------
2024-09-03 01:40:15,522 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-09-03 01:40:15,524 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-09-03 01:40:15,532 - pomdp.py - constructed quotient MDP having 7766 states and 32335 actions.
2024-09-03 01:40:15,785 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e63 to 1e14
> progress 0.0%, elapsed 3 s, estimated 253800610482364473841803259025174503886755580608512 s (8047964563748239425445842237208198677266432 years), iters = {MDP: 793}, opt = 0.244
> progress 0.0%, elapsed 6 s, estimated 504390593279590380748536201039129525237321239101440 s (15994120791463419714538147394930826415177728 years), iters = {MDP: 1595}, opt = 0.244
> progress 0.0%, elapsed 9 s, estimated 700497536275554246731585631004969700475068986949632 s (22212631160437415219020021678051476920860672 years), iters = {MDP: 2390}, opt = 0.244
> progress 0.0%, elapsed 12 s, estimated 932807104544361747114041070215961833145731752394752 s (29579119246079456352872718224661088460341248 years), iters = {MDP: 3197}, opt = 0.244
> progress 0.0%, elapsed 15 s, estimated 1154014048893412867222223442468513585695185428283392 s (36593545436752056538544404967907334362759168 years), iters = {MDP: 3990}, opt = 0.244
> progress 0.0%, elapsed 18 s, estimated 1091854085215386085662815539618985918847751636910080 s (34622465918803462553362566600420282689650688 years), iters = {MDP: 4783}, opt = 0.244
> progress 0.0%, elapsed 21 s, estimated 1268294804423967551896799532628334578152852632371200 s (40217364422373397562222753664933844928692224 years), iters = {MDP: 5590}, opt = 0.244
> progress 0.0%, elapsed 24 s, estimated 1446345072346362590277399077340917353651470296154112 s (45863301380846100995684377989379134821761024 years), iters = {MDP: 6399}, opt = 0.244
> progress 0.0%, elapsed 27 s, estimated 1593446243682908875593350802430479238091795674955776 s (50527848924496102799169707694389794556608512 years), iters = {MDP: 7210}, opt = 0.244
2024-09-03 01:40:42,988 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:40:43,090 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:40:43,090 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:40:54,102 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 224.1s | FSC size = 1512


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1512

------------------------------------

2024-09-03 01:41:15,205 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:41:16,023 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:41:16,023 - synthesizer_ar_storm.py - Additional memory needed
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 27.2 s
number of holes: 147, family size: 1e63, quotient: 7766 states / 32335 actions
explored: 0 %
MDP stats: avg MDP size: 2786, iterations: 7254

optimum: 0.243671
--------------------
2024-09-03 01:41:16,024 - synthesizer_pomdp.py - Assignment is None
2024-09-03 01:41:16,024 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-09-03 01:41:16,027 - pomdp.py - unfolding 2-FSC template into POMDP...
2024-09-03 01:41:16,035 - pomdp.py - constructed quotient MDP having 7726 states and 31867 actions.
2024-09-03 01:41:16,342 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e63 to 1e14
> progress 0.0%, elapsed 3 s, estimated 254031618370308618846201866187895898248428965068800 s (8055289775821557714244362596885280470335488 years), iters = {MDP: 794}, opt = 0.244
> progress 0.0%, elapsed 6 s, estimated 508235412311915945038205685756140883853889278836736 s (16116039203193681806605651119387583457525760 years), iters = {MDP: 1595}, opt = 0.244
> progress 0.0%, elapsed 9 s, estimated 761580601611335560637687236933285986207117818724352 s (24149562455965736810348986412488036293017600 years), iters = {MDP: 2391}, opt = 0.244
> progress 0.0%, elapsed 12 s, estimated 1015079276143110276384631617011736336473223960985600 s (32187952693528359326472118560205727065964544 years), iters = {MDP: 3195}, opt = 0.244
> progress 0.0%, elapsed 15 s, estimated 1268603497661796758684768033744699207811331996516352 s (40227153020731756969961902184277217713848320 years), iters = {MDP: 4000}, opt = 0.244
> progress 0.0%, elapsed 18 s, estimated 1521912174240168686494979871143386109296784795762688 s (48259518462714640195352043555267908934303744 years), iters = {MDP: 4804}, opt = 0.244
> progress 0.0%, elapsed 21 s, estimated 1767294035082536183218548416557288016186699023384576 s (56040526226615175108002665752605195870666752 years), iters = {MDP: 5601}, opt = 0.244
> progress 0.0%, elapsed 24 s, estimated 2018148358373508999687536275706777498450778277281792 s (63995064636399949655597373375707058360287232 years), iters = {MDP: 6403}, opt = 0.244
> progress 0.0%, elapsed 27 s, estimated 2269758521727152149521753732028929980034554768916480 s (71973570577345009700756450018528539074101248 years), iters = {MDP: 7212}, opt = 0.244
2024-09-03 01:41:45,246 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:41:45,341 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:41:45,341 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:41:56,350 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 290.4s | FSC size = 1512


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1512

------------------------------------

2024-09-03 01:42:21,459 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:42:22,286 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:42:22,286 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-09-03 01:42:22,287 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:42:22,288 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:42:22,289 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:42:22,290 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:42:22,290 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:42:22,291 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:42:22,292 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:42:22,293 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:42:22,293 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:42:22,294 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:42:22,295 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:42:22,296 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:42:22,296 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:42:22,297 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:42:22,298 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:42:22,299 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:42:22,299 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 16, Subfamilies - 0
> progress 0.0%, elapsed 30 s, estimated 2521192174277207165992175816049334779888056678744064 s (79946479397425386658708170713599003355774976 years), iters = {MDP: 8023}, opt = 0.244
> progress 0.0%, elapsed 33 s, estimated 2772932446477132637915840849858939755264483977592832 s (87929111062821309389463871675685281141358592 years), iters = {MDP: 8846}, opt = 0.244
> progress 0.0%, elapsed 36 s, estimated 3017957060493443048722601902213793460182870000664576 s (95698790604180700763528212902540338708611072 years), iters = {MDP: 9665}, opt = 0.244
> progress 0.0%, elapsed 39 s, estimated 3267998705887725837934079350391811099798068292222976 s (103627559166911658124457482023172587091132416 years), iters = {MDP: 10484}, opt = 0.244
> progress 0.0%, elapsed 42 s, estimated 3508416188331627302657484271724310719754035596886016 s (111251147524468142652462589423250594601107456 years), iters = {MDP: 11303}, opt = 0.244
> progress 0.0%, elapsed 45 s, estimated 3757700533825564627212189906966326516308003191259136 s (119155902264889795641442301484955361500725248 years), iters = {MDP: 12116}, opt = 0.244
> progress 0.0%, elapsed 48 s, estimated 4005988893995203406682685553904448963055074437758976 s (127029074517859072729719015546777878797484032 years), iters = {MDP: 12941}, opt = 0.244
> progress 0.0%, elapsed 51 s, estimated 4255543122651528392604676815050620299980212396883968 s (134942387197219949065639008436410559286476800 years), iters = {MDP: 13764}, opt = 0.244
> progress 0.0%, elapsed 54 s, estimated 4503680678304046437654435890494842820796727615815680 s (142810777470321084030690716982667328289243136 years), iters = {MDP: 14582}, opt = 0.244
> progress 0.0%, elapsed 57 s, estimated 4751269210121669417441662059906806834596064138362880 s (150661758311823605378185603634458809885261824 years), iters = {MDP: 15392}, opt = 0.244
2024-09-03 01:42:51,499 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:42:51,595 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:42:51,595 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:43:02,607 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 362.7s | FSC size = 1517


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

2024-09-03 01:43:33,720 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:43:34,546 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:43:34,546 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-09-03 01:43:34,547 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:43:34,548 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:43:34,549 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:43:34,549 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:43:34,550 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:43:34,551 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:43:34,552 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:43:34,552 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:43:34,553 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:43:34,554 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:43:34,555 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:43:34,555 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:43:34,556 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:43:34,557 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:43:34,558 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:43:34,559 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:43:34,559 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:43:34,560 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:43:34,561 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 18, Subfamilies - 0
> progress 0.0%, elapsed 60 s, estimated 4999706506574527066960172679774053609148585959489536 s (158539653303352583741079840838291500734349312 years), iters = {MDP: 16199}, opt = 0.244
> progress 0.0%, elapsed 63 s, estimated 5242591554896727161024658767046053093041836411322368 s (166241487661616158019105553841128718664204288 years), iters = {MDP: 17004}, opt = 0.244
> progress 0.0%, elapsed 66 s, estimated 5445273842227095347857464999651455596762832215998464 s (172668500831655729780979844482933522192924672 years), iters = {MDP: 17809}, opt = 0.244
> progress 0.0%, elapsed 69 s, estimated 5691468917425595735282423206942567903578327858806784 s (180475295453627433685002646464842604931448832 years), iters = {MDP: 18486}, opt = 0.244
> progress 0.0%, elapsed 72 s, estimated 5937419359661501679892049118951910301547211494785024 s (188274332815242940124931790554239881975955456 years), iters = {MDP: 19285}, opt = 0.244
> progress 0.0%, elapsed 75 s, estimated 6183345897669246590506236816169207828842196588560384 s (196072612178755923061720843532080748173459456 years), iters = {MDP: 20076}, opt = 0.244
> progress 0.0%, elapsed 78 s, estimated 6424077789355265581322231498012115101363316958691328 s (203706170387977729431329649230731426597437440 years), iters = {MDP: 20864}, opt = 0.244
> progress 0.0%, elapsed 81 s, estimated 6667714906900514409413179960558812014545613640171520 s (211431852704861553840283012049380666482098176 years), iters = {MDP: 21651}, opt = 0.244
> progress 0.0%, elapsed 84 s, estimated 6883360420855270349095498586002772777435336823275520 s (218269927094598849902108329864785771397906432 years), iters = {MDP: 22436}, opt = 0.244
> progress 0.0%, elapsed 87 s, estimated 6685615452082479484626889124526707222823750063882240 s (211999475268977655794039061924473272182767616 years), iters = {MDP: 23218}, opt = 0.244
2024-09-03 01:44:03,759 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:44:03,856 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:44:03,856 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:44:14,867 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 436.9s | FSC size = 1517


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

2024-09-03 01:44:47,983 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:44:48,809 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:44:48,809 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-09-03 01:44:48,810 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:44:48,811 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:44:48,812 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:44:48,812 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:44:48,813 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:44:48,814 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:44:48,815 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:44:48,815 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:44:48,816 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:44:48,817 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:44:48,818 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:44:48,818 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:44:48,819 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:44:48,820 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:44:48,821 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:44:48,821 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:44:48,822 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:44:48,823 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 17, Subfamilies - 0
> progress 0.0%, elapsed 90 s, estimated 6524642858626664333515398701822732876951581748101120 s (206895067815406686025763885556802299963113472 years), iters = {MDP: 23979}, opt = 0.244
> progress 0.0%, elapsed 93 s, estimated 5685960166773029270880548395035909150278952132018176 s (180300614116344160200591236021679276729303040 years), iters = {MDP: 24756}, opt = 0.244
> progress 0.0%, elapsed 96 s, estimated 5827013784771570770221659806935233748850350804172800 s (184773395001635290987875893736445809646370816 years), iters = {MDP: 25555}, opt = 0.244
> progress 0.0%, elapsed 99 s, estimated 6007218980530268339594547260443343954229723614150656 s (190487664273537165795080597304581171940687872 years), iters = {MDP: 26361}, opt = 0.244
> progress 0.0%, elapsed 102 s, estimated 6184423774994720007235241474860510914585589104771072 s (196106791444530693556607354189374030713192448 years), iters = {MDP: 27161}, opt = 0.244
> progress 0.0%, elapsed 105 s, estimated 6365321605536705097360668520476964151533263690661888 s (201843024021331344657373611792252576928366592 years), iters = {MDP: 27972}, opt = 0.244
> progress 0.0%, elapsed 108 s, estimated 6545949183551158132804068881409453031290771322437632 s (207570686946700884457389756942826727654031360 years), iters = {MDP: 28791}, opt = 0.244
> progress 0.0%, elapsed 111 s, estimated 6709709327387350235233430404963676879711778061156352 s (212763487042977900017667292660697707342462976 years), iters = {MDP: 29599}, opt = 0.244
> progress 0.0%, elapsed 114 s, estimated 6885781017165763737593747066349745499359529379299328 s (218346683700081280780141323740692113929535488 years), iters = {MDP: 30414}, opt = 0.244
2024-09-03 01:45:18,019 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:45:18,118 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:45:18,119 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:45:29,131 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 515.2s | FSC size = 1517


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

2024-09-03 01:46:06,250 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:46:07,072 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:46:07,073 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-09-03 01:46:07,073 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:46:07,074 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:46:07,074 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:46:07,075 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:46:07,076 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:46:07,077 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:46:07,078 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:46:07,078 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:46:07,079 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:46:07,080 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:46:07,081 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:46:07,081 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:46:07,082 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:46:07,083 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 13, Subfamilies - 0
> progress 0.0%, elapsed 117 s, estimated 7063500269929342729723288681453477878770972395307008 s (223982124236724430959710758596940625772281856 years), iters = {MDP: 31227}, opt = 0.244
> progress 0.0%, elapsed 120 s, estimated 7242385417209378818821019108902358246812310514434048 s (229654535045959534955660393637241578053435392 years), iters = {MDP: 32044}, opt = 0.244
> progress 0.0%, elapsed 123 s, estimated 7421643718040261439419802451147216134191536127606784 s (235338778476669916460722988618904424140505088 years), iters = {MDP: 32858}, opt = 0.244
> progress 0.0%, elapsed 126 s, estimated 7601499714880745326530621445909776835514217145565184 s (241041974723514236627492493361575107831529472 years), iters = {MDP: 33670}, opt = 0.244
> progress 0.0%, elapsed 129 s, estimated 7767936950706465524692070388880558182603246492712960 s (246319664849900617033508040747974843133067264 years), iters = {MDP: 34491}, opt = 0.244
> progress 0.0%, elapsed 132 s, estimated 7947061221849517413427276641365486888687406235516928 s (251999658227090198267706317185859310573322240 years), iters = {MDP: 35176}, opt = 0.244
> progress 0.0%, elapsed 135 s, estimated 8113837172640527728819216630429532122598953950642176 s (257288088934567718504997792883523695509766144 years), iters = {MDP: 35978}, opt = 0.244
> progress 0.0%, elapsed 138 s, estimated 8287829176950544551417666891001023028618616599740416 s (262805339198076622597986862911700592475766784 years), iters = {MDP: 36776}, opt = 0.244
> progress 0.0%, elapsed 141 s, estimated 8464779478871058654441186249748718738866744210751488 s (268416396463440449765354656373900629346615296 years), iters = {MDP: 37569}, opt = 0.244
> progress 0.0%, elapsed 144 s, estimated 8643450242081193671996196924896793275753640293826560 s (274082009198414329857282575567983097436700672 years), iters = {MDP: 38366}, opt = 0.244
2024-09-03 01:46:36,287 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:46:36,386 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:46:36,387 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:46:47,399 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 596.5s | FSC size = 1517


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

2024-09-03 01:47:27,521 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-09-03 01:47:28,343 - synthesizer_ar_storm.py - Resuming synthesis
2024-09-03 01:47:28,344 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-09-03 01:47:28,345 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:47:28,346 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e14 to 1e14
2024-09-03 01:47:28,346 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:47:28,347 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e13 to 1e13
2024-09-03 01:47:28,348 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:47:28,349 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e12 to 1e12
2024-09-03 01:47:28,349 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:47:28,350 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e11 to 1e11
2024-09-03 01:47:28,351 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:47:28,352 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e10 to 1e10
2024-09-03 01:47:28,352 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e9 to 1e9
2024-09-03 01:47:28,353 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e8 to 1e8
2024-09-03 01:47:28,354 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:47:28,355 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 1e7 to 1e7
2024-09-03 01:47:28,355 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 14, Subfamilies - 0
> progress 0.0%, elapsed 147 s, estimated 8821283693826061766539768191103494855546226301992960 s (279721070960998897321711479508269415691976704 years), iters = {MDP: 39161}, opt = 0.244
> progress 0.0%, elapsed 150 s, estimated 8997604039227224728382920250796087550447704824872960 s (285312152436175348091530249989378693081858048 years), iters = {MDP: 39964}, opt = 0.244
> progress 0.0%, elapsed 153 s, estimated 9175518144928400326028705563301130794607635639304192 s (290953771718937098766538291217119985864278016 years), iters = {MDP: 40770}, opt = 0.244
> progress 0.0%, elapsed 156 s, estimated 9346625650495611632193121497478893779464417102004224 s (296379555127334196431223747102517297869225984 years), iters = {MDP: 41566}, opt = 0.244
> progress 0.0%, elapsed 159 s, estimated 9514764950427257595925400505786519076457967414935552 s (301711217352462523656134042796366419239895040 years), iters = {MDP: 42374}, opt = 0.244
> progress 0.0%, elapsed 162 s, estimated 9644172892067559900362025085126069305195293803806720 s (305814716262923626488063495000340241206738944 years), iters = {MDP: 43178}, opt = 0.244
> progress 0.0%, elapsed 165 s, estimated 9821268245307862440575160531524610069487192496930816 s (311430373075464970261827470099203532355796992 years), iters = {MDP: 43992}, opt = 0.244
> progress 0.0%, elapsed 168 s, estimated 9998144719594260911772185931003987784351552647462912 s (317039089281908354606209356179592028283207680 years), iters = {MDP: 44792}, opt = 0.244
> progress 0.0%, elapsed 171 s, estimated 10169492854563103547299425740899960271239099805859840 s (322472502998576379148419810475067897886539776 years), iters = {MDP: 45593}, opt = 0.244
> progress 0.0%, elapsed 174 s, estimated 10344043138037943394369926256486070193121319626735616 s (328007456178270678366970101352919401039396864 years), iters = {MDP: 46402}, opt = 0.244
2024-09-03 01:47:57,559 - synthesizer_ar_storm.py - Pausing synthesis
2024-09-03 01:47:57,657 - storm_pomdp_control.py - Interactive Storm resumed
2024-09-03 01:47:57,658 - storm_pomdp_control.py - Updating FSC values in Storm
2024-09-03 01:48:08,670 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.2591092020812111 | Time elapsed = 680.7s | FSC size = 1517


------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

2024-09-03 01:48:52,619 - synthesizer_ar_storm.py - Terminating controller synthesis
--------------------
Synthesis summary:
optimality objective: Pmax=? [F "goal"] 

method: AR, synthesis time: 174.9 s
number of holes: 147, family size: 1e63, quotient: 7726 states / 31867 actions
explored: 0 %
MDP stats: avg MDP size: 2753, iterations: 46602

optimum: 0.243671
--------------------
2024-09-03 01:48:52,620 - synthesizer_pomdp.py - Assignment is None
2024-09-03 01:48:52,621 - storm_pomdp_control.py - Storm POMDP analysis completed
2024-09-03 01:48:52,700 - synthesizer_rl.py - RL Environment initialized
2024-09-03 01:48:53,181 - periodic_fsc_neural_ppo.py - Agent initialized
2024-09-03 01:48:53,191 - periodic_fsc_neural_ppo.py - Replay buffer initialized
2024-09-03 01:48:53,910 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:54,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:54,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:54,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:54,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:54,957 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:55,124 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:55,307 - father_agent.py - Training agent
2024-09-03 01:48:55,372 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:55,465 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:55,532 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:48:57,657 - father_agent.py - Step: 0, Training loss: 0.1878882497549057
2024-09-03 01:49:00,109 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,141 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,264 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,324 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,357 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,424 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,476 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,507 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,563 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,632 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,663 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,699 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,729 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,778 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,808 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,891 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,922 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:00,975 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,006 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,060 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,129 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,163 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,193 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,223 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,254 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,332 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,453 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,513 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,581 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,611 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,645 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,707 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,762 - father_agent.py - Average Return = -28.149999618530273
2024-09-03 01:49:01,762 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:01,762 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:01,811 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,912 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:01,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,043 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,186 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,307 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,377 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,401 - father_agent.py - Step: 10, Training loss: 0.19373352825641632
2024-09-03 01:49:02,448 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,510 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,573 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,661 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,726 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:02,908 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,025 - father_agent.py - Step: 20, Training loss: 0.18399295210838318
2024-09-03 01:49:03,028 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,126 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,189 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,252 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,316 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,428 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,491 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,554 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,654 - father_agent.py - Step: 30, Training loss: 0.1498594582080841
2024-09-03 01:49:03,704 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:03,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,051 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,177 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,242 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,278 - father_agent.py - Step: 40, Training loss: 0.14080865681171417
2024-09-03 01:49:04,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,375 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,445 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,514 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,672 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,787 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,906 - father_agent.py - Step: 50, Training loss: 0.1520524024963379
2024-09-03 01:49:04,925 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:04,987 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,049 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,244 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,325 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,388 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,451 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,532 - father_agent.py - Step: 60, Training loss: 0.15340924263000488
2024-09-03 01:49:05,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,613 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,739 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,815 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:05,946 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,015 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,079 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,141 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,153 - father_agent.py - Step: 70, Training loss: 0.18656188249588013
2024-09-03 01:49:06,245 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,325 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,476 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,539 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,600 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,737 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,783 - father_agent.py - Step: 80, Training loss: 0.19093665480613708
2024-09-03 01:49:06,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,874 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:06,938 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,001 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,064 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,127 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,202 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,318 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,406 - father_agent.py - Step: 90, Training loss: 0.2562386989593506
2024-09-03 01:49:07,481 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,550 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,620 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,684 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,757 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,848 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,935 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:07,997 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,029 - father_agent.py - Step: 100, Training loss: 0.39163362979888916
2024-09-03 01:49:08,310 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,353 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,384 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,466 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,500 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,537 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,571 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,602 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,631 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,667 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,698 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,798 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,840 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,883 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,955 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:08,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,055 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,086 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,118 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,183 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,279 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,308 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,396 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,430 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,460 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,514 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,553 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,584 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,631 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,695 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,778 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,807 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,838 - father_agent.py - Average Return = -26.5
2024-09-03 01:49:09,838 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:09,838 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:09,907 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:09,972 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,035 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,097 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,165 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,228 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,290 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,360 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,423 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,461 - father_agent.py - Step: 110, Training loss: 0.3290274441242218
2024-09-03 01:49:10,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,658 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,799 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:10,988 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,056 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,074 - father_agent.py - Step: 120, Training loss: 0.30374404788017273
2024-09-03 01:49:11,152 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,215 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,278 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,489 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,590 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,673 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,701 - father_agent.py - Step: 130, Training loss: 0.3335733115673065
2024-09-03 01:49:11,736 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,810 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,874 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:11,965 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,027 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,150 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,248 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,323 - father_agent.py - Step: 140, Training loss: 0.3789965510368347
2024-09-03 01:49:12,332 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,459 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,522 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,584 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,798 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,912 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:12,948 - father_agent.py - Step: 150, Training loss: 0.34952765703201294
2024-09-03 01:49:12,992 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,144 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,237 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,347 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,464 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,567 - father_agent.py - Step: 160, Training loss: 0.30652564764022827
2024-09-03 01:49:13,599 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,661 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,917 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:13,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,041 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,141 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,191 - father_agent.py - Step: 170, Training loss: 0.35562464594841003
2024-09-03 01:49:14,203 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,288 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,353 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,414 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,519 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,605 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,715 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:14,816 - father_agent.py - Step: 180, Training loss: 0.3713265061378479
2024-09-03 01:49:14,905 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,159 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,290 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,430 - father_agent.py - Step: 190, Training loss: 0.3684496283531189
2024-09-03 01:49:15,460 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,522 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,641 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,718 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,780 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,844 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:15,960 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,048 - father_agent.py - Step: 200, Training loss: 0.42262330651283264
2024-09-03 01:49:16,319 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,363 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,420 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,452 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,514 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,548 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,578 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,663 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,694 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,776 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,805 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,835 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,873 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,904 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,934 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:16,964 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,069 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,099 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,128 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,158 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,215 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,246 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,276 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,307 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,337 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,420 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,479 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,510 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,550 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,584 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,624 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,759 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,809 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,892 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:17,894 - father_agent.py - Average Return = -28.100000381469727
2024-09-03 01:49:17,894 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:17,894 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:17,941 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,005 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,067 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,129 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,192 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,278 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,504 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,520 - father_agent.py - Step: 210, Training loss: 0.33656010031700134
2024-09-03 01:49:18,567 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,652 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,878 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:18,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,004 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,144 - father_agent.py - Step: 220, Training loss: 0.3397911489009857
2024-09-03 01:49:19,176 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,288 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,526 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,610 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,672 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,734 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,761 - father_agent.py - Step: 230, Training loss: 0.3980534076690674
2024-09-03 01:49:19,855 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,918 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:19,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,161 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,224 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,384 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,409 - father_agent.py - Step: 240, Training loss: 0.46970134973526
2024-09-03 01:49:20,454 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,517 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,581 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,643 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,705 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:20,994 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,036 - father_agent.py - Step: 250, Training loss: 0.3939366340637207
2024-09-03 01:49:21,079 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,148 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,212 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,306 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,520 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,585 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,647 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,668 - father_agent.py - Step: 260, Training loss: 0.38236650824546814
2024-09-03 01:49:21,801 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,870 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,934 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:21,998 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,060 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,146 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,208 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,270 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,293 - father_agent.py - Step: 270, Training loss: 0.31452178955078125
2024-09-03 01:49:22,425 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,495 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,559 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,621 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,683 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,769 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,861 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,917 - father_agent.py - Step: 280, Training loss: 0.3838406503200531
2024-09-03 01:49:22,923 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:22,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,089 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,152 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,216 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,301 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,502 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,540 - father_agent.py - Step: 290, Training loss: 0.3998867869377136
2024-09-03 01:49:23,566 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,629 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,773 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,874 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,936 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:23,999 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,062 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,165 - father_agent.py - Step: 300, Training loss: 0.448944091796875
2024-09-03 01:49:24,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,481 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,529 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,566 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,595 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,626 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,657 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,712 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,751 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,782 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,851 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,882 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,913 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,943 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:24,981 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,020 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,103 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,133 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,171 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,201 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,248 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,296 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,361 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,391 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,420 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,491 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,524 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,557 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,588 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,673 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,718 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,749 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,788 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,836 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,866 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,936 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:25,966 - father_agent.py - Average Return = -26.024999618530273
2024-09-03 01:49:25,966 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:25,966 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:26,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,077 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,139 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,224 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,562 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,591 - father_agent.py - Step: 310, Training loss: 0.37230682373046875
2024-09-03 01:49:26,676 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,799 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,864 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:26,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,063 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,221 - father_agent.py - Step: 320, Training loss: 0.4146956205368042
2024-09-03 01:49:27,245 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,315 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,378 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,548 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,610 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,745 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,807 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,854 - father_agent.py - Step: 330, Training loss: 0.5138735771179199
2024-09-03 01:49:27,887 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:27,950 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,013 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,179 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,269 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,339 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,434 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,476 - father_agent.py - Step: 340, Training loss: 0.46317988634109497
2024-09-03 01:49:28,496 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,559 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,624 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,693 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,773 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,843 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,909 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:28,970 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,091 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,107 - father_agent.py - Step: 350, Training loss: 0.4571651816368103
2024-09-03 01:49:29,154 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,334 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,504 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,567 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,735 - father_agent.py - Step: 360, Training loss: 0.46928346157073975
2024-09-03 01:49:29,739 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,874 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:29,937 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,095 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,157 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,277 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,359 - father_agent.py - Step: 370, Training loss: 0.4903445243835449
2024-09-03 01:49:30,394 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,456 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,520 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,583 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,743 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,807 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,868 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:30,982 - father_agent.py - Step: 380, Training loss: 0.503323495388031
2024-09-03 01:49:31,113 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,175 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,337 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,443 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,508 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,603 - father_agent.py - Step: 390, Training loss: 0.48749443888664246
2024-09-03 01:49:31,610 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,736 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,817 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:31,960 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,211 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,230 - father_agent.py - Step: 400, Training loss: 0.46747344732284546
2024-09-03 01:49:32,503 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,536 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,568 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,630 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,702 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,732 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,793 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,896 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,926 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,957 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:32,986 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,024 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,068 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,104 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,163 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,243 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,280 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,322 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,398 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,429 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,467 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,561 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,596 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,661 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,690 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,720 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,749 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,805 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,839 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,881 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,928 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,961 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:33,992 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,021 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,056 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,057 - father_agent.py - Average Return = -27.524999618530273
2024-09-03 01:49:34,057 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:34,058 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:34,105 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,167 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,290 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,354 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,442 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,511 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,599 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,676 - father_agent.py - Step: 410, Training loss: 0.4776976406574249
2024-09-03 01:49:34,714 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,777 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:34,946 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,010 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,073 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,135 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,254 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,301 - father_agent.py - Step: 420, Training loss: 0.4731210768222809
2024-09-03 01:49:35,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,378 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,496 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,558 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,622 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,684 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,753 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,827 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:35,922 - father_agent.py - Step: 430, Training loss: 0.5231660604476929
2024-09-03 01:49:35,952 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,092 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,154 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,280 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,397 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,521 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,544 - father_agent.py - Step: 440, Training loss: 0.5179371237754822
2024-09-03 01:49:36,642 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,753 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,816 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,893 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:36,989 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,165 - father_agent.py - Step: 450, Training loss: 0.45145198702812195
2024-09-03 01:49:37,216 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,279 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,365 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,443 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,505 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,629 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,691 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,789 - father_agent.py - Step: 460, Training loss: 0.5416383743286133
2024-09-03 01:49:37,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,921 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:37,997 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,076 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,139 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,208 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,290 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,353 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,410 - father_agent.py - Step: 470, Training loss: 0.4945254325866699
2024-09-03 01:49:38,451 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,600 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,672 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,736 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,805 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,876 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:38,938 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,002 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,033 - father_agent.py - Step: 480, Training loss: 0.5283688902854919
2024-09-03 01:49:39,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,126 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,240 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,364 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,554 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,653 - father_agent.py - Step: 490, Training loss: 0.4921032190322876
2024-09-03 01:49:39,742 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,825 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:39,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,052 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,183 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,266 - father_agent.py - Step: 500, Training loss: 0.4838740825653076
2024-09-03 01:49:40,568 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,610 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,657 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,688 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,718 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,749 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,849 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,913 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,943 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:40,984 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,061 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,101 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,132 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,176 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,271 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,312 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,471 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,542 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,603 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,655 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,684 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,715 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,792 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,825 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,898 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:41,977 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,011 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,042 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,076 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,124 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,160 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,190 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,222 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,262 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,263 - father_agent.py - Average Return = -31.575000762939453
2024-09-03 01:49:42,263 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:42,263 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:42,338 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,424 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,488 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,548 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,611 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,683 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,774 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,881 - father_agent.py - Step: 510, Training loss: 0.4941893219947815
2024-09-03 01:49:42,893 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:42,958 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,022 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,085 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,211 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,273 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,335 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,409 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,478 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,510 - father_agent.py - Step: 520, Training loss: 0.5019700527191162
2024-09-03 01:49:43,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,729 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,791 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,854 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:43,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,071 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,130 - father_agent.py - Step: 530, Training loss: 0.5255072712898254
2024-09-03 01:49:44,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,219 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,468 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,650 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,719 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,751 - father_agent.py - Step: 540, Training loss: 0.497864305973053
2024-09-03 01:49:44,787 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:44,937 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,026 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,088 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,217 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,280 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,372 - father_agent.py - Step: 550, Training loss: 0.4580361843109131
2024-09-03 01:49:45,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,538 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,660 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,722 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:45,947 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,019 - father_agent.py - Step: 560, Training loss: 0.5012224316596985
2024-09-03 01:49:46,033 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,147 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,232 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,312 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,470 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,533 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,594 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,637 - father_agent.py - Step: 570, Training loss: 0.5187682509422302
2024-09-03 01:49:46,663 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,833 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:46,955 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,073 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,135 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,196 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,249 - father_agent.py - Step: 580, Training loss: 0.5044458508491516
2024-09-03 01:49:47,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,328 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,390 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,508 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,579 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,655 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,716 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,843 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,867 - father_agent.py - Step: 590, Training loss: 0.5100390315055847
2024-09-03 01:49:47,904 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:47,966 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,068 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,158 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,243 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,387 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,460 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,495 - father_agent.py - Step: 600, Training loss: 0.4957880675792694
2024-09-03 01:49:48,768 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,799 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,841 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,897 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,928 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,958 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:48,998 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,040 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,091 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,122 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,182 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,323 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,381 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,445 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,515 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,554 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,588 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,648 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,679 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,753 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,784 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,826 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,860 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,935 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:49,975 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,005 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,052 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,089 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,126 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,157 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,201 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,232 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,380 - father_agent.py - Average Return = -28.5
2024-09-03 01:49:50,381 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:50,381 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:50,488 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,602 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,664 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,726 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,789 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,852 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:50,948 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,005 - father_agent.py - Step: 610, Training loss: 0.4737388789653778
2024-09-03 01:49:51,019 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,116 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,198 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,281 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,343 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,406 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,581 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,630 - father_agent.py - Step: 620, Training loss: 0.4350508153438568
2024-09-03 01:49:51,645 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,742 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,853 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:51,952 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,016 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,093 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,253 - father_agent.py - Step: 630, Training loss: 0.516944408416748
2024-09-03 01:49:52,288 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,652 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,798 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,861 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:52,873 - father_agent.py - Step: 640, Training loss: 0.5504809617996216
2024-09-03 01:49:52,965 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,038 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,213 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,321 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,384 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,447 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,497 - father_agent.py - Step: 650, Training loss: 0.5095781087875366
2024-09-03 01:49:53,539 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,748 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,809 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:53,991 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,052 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,107 - father_agent.py - Step: 660, Training loss: 0.5126031041145325
2024-09-03 01:49:54,131 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,256 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,319 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,406 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,494 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,650 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,712 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:54,728 - father_agent.py - Step: 670, Training loss: 0.5095627903938293
2024-09-03 01:49:54,986 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,056 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,121 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,204 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,301 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,350 - father_agent.py - Step: 680, Training loss: 0.5303046107292175
2024-09-03 01:49:55,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,572 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,681 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,785 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,854 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:55,966 - father_agent.py - Step: 690, Training loss: 0.42797237634658813
2024-09-03 01:49:55,998 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,060 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,122 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,200 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,344 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,406 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,533 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,590 - father_agent.py - Step: 700, Training loss: 0.5138200521469116
2024-09-03 01:49:56,875 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,947 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:56,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,068 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,103 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,184 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,248 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,296 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,335 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,369 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,405 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,436 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,500 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,556 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,591 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,649 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,680 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,717 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,758 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,796 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,827 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,867 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,898 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,961 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:57,991 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,022 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,063 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,111 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,195 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,257 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,315 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,345 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,417 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,418 - father_agent.py - Average Return = -27.125
2024-09-03 01:49:58,419 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:49:58,419 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:49:58,542 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,625 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,689 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,752 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,815 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:58,954 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,037 - father_agent.py - Step: 710, Training loss: 0.4912310540676117
2024-09-03 01:49:59,066 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,131 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,215 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,441 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,503 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,567 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,661 - father_agent.py - Step: 720, Training loss: 0.5523315668106079
2024-09-03 01:49:59,664 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,727 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,878 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:49:59,984 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,048 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,110 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,173 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,238 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,291 - father_agent.py - Step: 730, Training loss: 0.46851539611816406
2024-09-03 01:50:00,336 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,465 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,529 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,611 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,737 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,841 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:00,919 - father_agent.py - Step: 740, Training loss: 0.5095435380935669
2024-09-03 01:50:00,945 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,007 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,069 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,234 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,366 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,427 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,511 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,545 - father_agent.py - Step: 750, Training loss: 0.47802987694740295
2024-09-03 01:50:01,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,673 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,751 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,871 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,933 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:01,996 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,146 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,169 - father_agent.py - Step: 760, Training loss: 0.4489959180355072
2024-09-03 01:50:02,208 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,277 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,507 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,570 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,666 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,787 - father_agent.py - Step: 770, Training loss: 0.5382214188575745
2024-09-03 01:50:02,799 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:02,939 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,119 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,181 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,255 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,331 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,409 - father_agent.py - Step: 780, Training loss: 0.501678466796875
2024-09-03 01:50:03,421 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,662 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,724 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,844 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,907 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:03,971 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,030 - father_agent.py - Step: 790, Training loss: 0.5166821479797363
2024-09-03 01:50:04,053 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,177 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,239 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,301 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,370 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,435 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,498 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,643 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,654 - father_agent.py - Step: 800, Training loss: 0.5313135981559753
2024-09-03 01:50:04,930 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,962 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:04,993 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,033 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,074 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,112 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,143 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,265 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,325 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,358 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,390 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,456 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,529 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,636 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,710 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,770 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,800 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,845 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,908 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:05,998 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,112 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,172 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,278 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,319 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,359 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,455 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,485 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,529 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,559 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,561 - father_agent.py - Average Return = -29.25
2024-09-03 01:50:06,561 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:06,561 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:06,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,729 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,857 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,919 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:06,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,045 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,187 - father_agent.py - Step: 810, Training loss: 0.4849037826061249
2024-09-03 01:50:07,229 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,292 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,355 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,423 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,563 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,801 - father_agent.py - Step: 820, Training loss: 0.4443478584289551
2024-09-03 01:50:07,807 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,904 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:07,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,044 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,127 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,193 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,290 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,353 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,443 - father_agent.py - Step: 830, Training loss: 0.5143656730651855
2024-09-03 01:50:08,487 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,614 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,758 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,821 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:08,950 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,012 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,063 - father_agent.py - Step: 840, Training loss: 0.5762588977813721
2024-09-03 01:50:09,072 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,165 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,266 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,351 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,450 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,512 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,586 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,657 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,689 - father_agent.py - Step: 850, Training loss: 0.5263181924819946
2024-09-03 01:50:09,732 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,857 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:09,921 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,082 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,212 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,288 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,307 - father_agent.py - Step: 860, Training loss: 0.5205821990966797
2024-09-03 01:50:10,373 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,434 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,508 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,578 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,640 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,724 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,823 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,893 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:10,934 - father_agent.py - Step: 870, Training loss: 0.5659432411193848
2024-09-03 01:50:10,955 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,017 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,080 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,150 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,220 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,413 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,557 - father_agent.py - Step: 880, Training loss: 0.5909163951873779
2024-09-03 01:50:11,588 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,651 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,764 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,879 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:11,966 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,049 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,110 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,182 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,200 - father_agent.py - Step: 890, Training loss: 0.5785180926322937
2024-09-03 01:50:12,335 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,398 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,462 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,525 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,617 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,680 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,778 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:12,822 - father_agent.py - Step: 900, Training loss: 0.5186766982078552
2024-09-03 01:50:13,097 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,138 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,200 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,233 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,267 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,327 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,357 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,402 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,446 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,476 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,578 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,624 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,683 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,712 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,746 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,785 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,815 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,851 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,893 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,922 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,953 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:13,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,018 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,067 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,102 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,140 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,169 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,220 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,296 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,328 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,372 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,482 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,532 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,561 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,616 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,646 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,689 - father_agent.py - Average Return = -28.950000762939453
2024-09-03 01:50:14,689 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:14,689 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:14,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,827 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:14,952 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,050 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,140 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,203 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,266 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,318 - father_agent.py - Step: 910, Training loss: 0.47416526079177856
2024-09-03 01:50:15,330 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,394 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,548 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,611 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,680 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,744 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,834 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,922 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:15,952 - father_agent.py - Step: 920, Training loss: 0.48148345947265625
2024-09-03 01:50:15,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,168 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,270 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,334 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,489 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,572 - father_agent.py - Step: 930, Training loss: 0.5610544085502625
2024-09-03 01:50:16,608 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,670 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,733 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,797 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,934 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:16,995 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,094 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,192 - father_agent.py - Step: 940, Training loss: 0.5206114053726196
2024-09-03 01:50:17,210 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,274 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,364 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,521 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,660 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,724 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,819 - father_agent.py - Step: 950, Training loss: 0.5299399495124817
2024-09-03 01:50:17,883 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:17,945 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,007 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,097 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,264 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,325 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,418 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,434 - father_agent.py - Step: 960, Training loss: 0.5544402599334717
2024-09-03 01:50:18,501 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,573 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,730 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,793 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,855 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,918 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:18,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,052 - father_agent.py - Step: 970, Training loss: 0.5038151741027832
2024-09-03 01:50:19,121 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,185 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,246 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,308 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,638 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,671 - father_agent.py - Step: 980, Training loss: 0.4721132516860962
2024-09-03 01:50:19,721 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,837 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,902 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:19,974 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,067 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,129 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,241 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,299 - father_agent.py - Step: 990, Training loss: 0.5776262879371643
2024-09-03 01:50:20,316 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,411 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,573 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,703 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,822 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,901 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:20,920 - father_agent.py - Step: 1000, Training loss: 0.44065266847610474
2024-09-03 01:50:21,204 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,237 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,268 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,331 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,378 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,409 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,466 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,495 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,530 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,561 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,698 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,743 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,777 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,820 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,850 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,901 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,932 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:21,976 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,007 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,054 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,094 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,125 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,154 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,185 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,270 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,377 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,407 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,444 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,479 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,509 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,538 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,568 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,601 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,705 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,706 - father_agent.py - Average Return = -26.850000381469727
2024-09-03 01:50:22,706 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:22,706 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:22,814 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,896 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:22,958 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,021 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,160 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,231 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,327 - father_agent.py - Step: 1010, Training loss: 0.5021006464958191
2024-09-03 01:50:23,407 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,530 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,599 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,696 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:23,939 - father_agent.py - Step: 1020, Training loss: 0.5951109528541565
2024-09-03 01:50:24,006 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,083 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,166 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,319 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,392 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,455 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,518 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,556 - father_agent.py - Step: 1030, Training loss: 0.5830598473548889
2024-09-03 01:50:24,587 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:24,977 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,114 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,174 - father_agent.py - Step: 1040, Training loss: 0.49059349298477173
2024-09-03 01:50:25,308 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,372 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,451 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,547 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,609 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,673 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,793 - father_agent.py - Step: 1050, Training loss: 0.4625988006591797
2024-09-03 01:50:25,796 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,895 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:25,969 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,092 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,155 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,330 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,422 - father_agent.py - Step: 1060, Training loss: 0.5367069244384766
2024-09-03 01:50:26,438 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,500 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,575 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,639 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,703 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,838 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:26,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,053 - father_agent.py - Step: 1070, Training loss: 0.4684048891067505
2024-09-03 01:50:27,057 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,119 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,374 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,436 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,519 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,641 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,678 - father_agent.py - Step: 1080, Training loss: 0.4705517590045929
2024-09-03 01:50:27,716 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,828 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:27,939 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,002 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,095 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,159 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,243 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,304 - father_agent.py - Step: 1090, Training loss: 0.42435163259506226
2024-09-03 01:50:28,323 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,396 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,502 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,576 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,638 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,713 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,888 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:28,925 - father_agent.py - Step: 1100, Training loss: 0.5026230812072754
2024-09-03 01:50:29,247 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,278 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,375 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,439 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,530 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,563 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,653 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,721 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,755 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,832 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,871 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,902 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,966 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:29,996 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,028 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,067 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,116 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,147 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,178 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,211 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,267 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,340 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,399 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,428 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,488 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,525 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,556 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,597 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,644 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,760 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,832 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,891 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,931 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,961 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,993 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:30,995 - father_agent.py - Average Return = -33.474998474121094
2024-09-03 01:50:30,995 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:30,995 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:31,091 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,229 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,292 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,388 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,547 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,627 - father_agent.py - Step: 1110, Training loss: 0.6015283465385437
2024-09-03 01:50:31,652 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,849 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:31,986 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,087 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,173 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,236 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,263 - father_agent.py - Step: 1120, Training loss: 0.5726705193519592
2024-09-03 01:50:32,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,467 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,537 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,614 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,677 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,738 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,802 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:32,881 - father_agent.py - Step: 1130, Training loss: 0.5635099411010742
2024-09-03 01:50:32,956 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,020 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,162 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,289 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,402 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,501 - father_agent.py - Step: 1140, Training loss: 0.5386829376220703
2024-09-03 01:50:33,515 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,585 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,647 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,711 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:33,884 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,008 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,070 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,125 - father_agent.py - Step: 1150, Training loss: 0.5750888586044312
2024-09-03 01:50:34,168 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,238 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,321 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,393 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,463 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,615 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,678 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,752 - father_agent.py - Step: 1160, Training loss: 0.4646713137626648
2024-09-03 01:50:34,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,833 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,909 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:34,972 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,044 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,107 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,219 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,289 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,381 - father_agent.py - Step: 1170, Training loss: 0.5232896208763123
2024-09-03 01:50:35,397 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,459 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,528 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,756 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,851 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:35,999 - father_agent.py - Step: 1180, Training loss: 0.4856263995170593
2024-09-03 01:50:36,024 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,138 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,204 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,268 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,453 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,555 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,657 - father_agent.py - Step: 1190, Training loss: 0.5412150621414185
2024-09-03 01:50:36,747 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,816 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:36,953 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,045 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,108 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,277 - father_agent.py - Step: 1200, Training loss: 0.39620551466941833
2024-09-03 01:50:37,574 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,607 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,690 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,749 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,779 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,809 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,886 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:37,947 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,017 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,063 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,121 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,152 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,204 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,254 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,335 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,409 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,444 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,545 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,602 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,634 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,665 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,696 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,780 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,816 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,850 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,900 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,938 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:38,968 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,015 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,051 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,088 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,122 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,167 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,198 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,252 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,319 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,363 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,365 - father_agent.py - Average Return = -33.57500076293945
2024-09-03 01:50:39,365 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:39,365 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:39,434 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,594 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,714 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,777 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,846 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:39,987 - father_agent.py - Step: 1210, Training loss: 0.5686982274055481
2024-09-03 01:50:39,993 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,056 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,120 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,253 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,327 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,407 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,490 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,553 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,608 - father_agent.py - Step: 1220, Training loss: 0.5179093480110168
2024-09-03 01:50:40,615 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,678 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,740 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,813 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,892 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:40,955 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,020 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,120 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,201 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,241 - father_agent.py - Step: 1230, Training loss: 0.5064115524291992
2024-09-03 01:50:41,320 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,461 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,815 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,859 - father_agent.py - Step: 1240, Training loss: 0.45854446291923523
2024-09-03 01:50:41,878 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:41,942 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,015 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,078 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,151 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,347 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,429 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,484 - father_agent.py - Step: 1250, Training loss: 0.3520123362541199
2024-09-03 01:50:42,527 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,590 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,842 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,907 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:42,992 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,054 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,111 - father_agent.py - Step: 1260, Training loss: 0.5266465544700623
2024-09-03 01:50:43,187 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,344 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,489 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,592 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,704 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,731 - father_agent.py - Step: 1270, Training loss: 0.47388696670532227
2024-09-03 01:50:43,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,894 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:43,985 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,066 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,138 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,247 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,353 - father_agent.py - Step: 1280, Training loss: 0.49471214413642883
2024-09-03 01:50:44,457 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,544 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,608 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,705 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,898 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,960 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:44,972 - father_agent.py - Step: 1290, Training loss: 0.4937083125114441
2024-09-03 01:50:45,023 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,086 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,148 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,209 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,271 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,448 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,536 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:45,597 - father_agent.py - Step: 1300, Training loss: 0.4903642535209656
2024-09-03 01:50:45,924 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,008 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,059 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,157 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,211 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,241 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,276 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,312 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,387 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,418 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,449 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,479 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,539 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,590 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,637 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,667 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,697 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,749 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,809 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,839 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,873 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:46,943 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,006 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,066 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,146 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,185 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,230 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,270 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,348 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,426 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,479 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,516 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,551 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,590 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,651 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,682 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,722 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,723 - father_agent.py - Average Return = -35.29999923706055
2024-09-03 01:50:47,724 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:47,724 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:47,801 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,883 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:47,959 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,119 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,225 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,320 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,343 - father_agent.py - Step: 1310, Training loss: 0.5041614174842834
2024-09-03 01:50:48,431 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,495 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,572 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,663 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,779 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,857 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:48,962 - father_agent.py - Step: 1320, Training loss: 0.5191116333007812
2024-09-03 01:50:49,024 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,129 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,191 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,255 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,367 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,470 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,533 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,583 - father_agent.py - Step: 1330, Training loss: 0.45517972111701965
2024-09-03 01:50:49,652 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,733 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,875 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:49,938 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,003 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,100 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,162 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,210 - father_agent.py - Step: 1340, Training loss: 0.506824254989624
2024-09-03 01:50:50,371 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,440 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,503 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,566 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,688 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,829 - father_agent.py - Step: 1350, Training loss: 0.5472697019577026
2024-09-03 01:50:50,846 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:50,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,041 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,230 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,307 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,417 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,453 - father_agent.py - Step: 1360, Training loss: 0.535137414932251
2024-09-03 01:50:51,478 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,673 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,826 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,892 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:51,962 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,076 - father_agent.py - Step: 1370, Training loss: 0.4651934504508972
2024-09-03 01:50:52,097 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,205 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,267 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,332 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,594 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,658 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,704 - father_agent.py - Step: 1380, Training loss: 0.4885908365249634
2024-09-03 01:50:52,775 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,866 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:52,968 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,075 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,138 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,199 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,312 - father_agent.py - Step: 1390, Training loss: 0.5360678434371948
2024-09-03 01:50:53,321 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,384 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,447 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,537 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,695 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,775 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,853 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:53,935 - father_agent.py - Step: 1400, Training loss: 0.5443636775016785
2024-09-03 01:50:54,240 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,318 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,350 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,424 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,471 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,500 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,532 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,564 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,631 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,699 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,758 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,787 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,818 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,874 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,924 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:54,971 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,001 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,068 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,098 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,128 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,179 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,220 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,305 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,336 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,387 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,418 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,464 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,556 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,586 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,631 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,686 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,721 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,751 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,837 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,872 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,930 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:55,932 - father_agent.py - Average Return = -31.600000381469727
2024-09-03 01:50:55,932 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:50:55,932 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:50:55,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,164 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,411 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,541 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,558 - father_agent.py - Step: 1410, Training loss: 0.5105781555175781
2024-09-03 01:50:56,625 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,704 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,767 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,840 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:56,974 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,129 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,186 - father_agent.py - Step: 1420, Training loss: 0.4629695415496826
2024-09-03 01:50:57,203 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,275 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,359 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,546 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,632 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,704 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,793 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,816 - father_agent.py - Step: 1430, Training loss: 0.5722079277038574
2024-09-03 01:50:57,898 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:57,962 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,070 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,139 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,287 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,422 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,434 - father_agent.py - Step: 1440, Training loss: 0.507278323173523
2024-09-03 01:50:58,484 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,619 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,690 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,762 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,845 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:58,937 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,002 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,055 - father_agent.py - Step: 1450, Training loss: 0.4929760694503784
2024-09-03 01:50:59,082 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,153 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,230 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,431 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,497 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,560 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,622 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,679 - father_agent.py - Step: 1460, Training loss: 0.5479941964149475
2024-09-03 01:50:59,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,802 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,903 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:50:59,975 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,072 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,156 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,258 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,322 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,333 - father_agent.py - Step: 1470, Training loss: 0.5528720617294312
2024-09-03 01:51:00,419 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,612 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,736 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,909 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:00,963 - father_agent.py - Step: 1480, Training loss: 0.5919381380081177
2024-09-03 01:51:00,987 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,052 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,194 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,264 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,410 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,533 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,594 - father_agent.py - Step: 1490, Training loss: 0.5097617506980896
2024-09-03 01:51:01,611 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,682 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,744 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,819 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:01,986 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,080 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,205 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,216 - father_agent.py - Step: 1500, Training loss: 0.4305880665779114
2024-09-03 01:51:02,494 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,527 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,597 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,644 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,685 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,719 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,755 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,838 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,888 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:02,934 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,000 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,064 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,118 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,191 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,237 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,269 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,311 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,384 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,415 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,445 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,500 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,529 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,560 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,599 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,634 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,687 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,752 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,782 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,820 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,853 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,882 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,913 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,945 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:03,997 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,077 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,115 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,202 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,204 - father_agent.py - Average Return = -31.625
2024-09-03 01:51:04,204 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:04,204 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:51:04,311 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,375 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,439 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,511 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,635 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,719 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,834 - father_agent.py - Step: 1510, Training loss: 0.5041965246200562
2024-09-03 01:51:04,853 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:04,979 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,042 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,160 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,244 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,441 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,457 - father_agent.py - Step: 1520, Training loss: 0.5174283981323242
2024-09-03 01:51:05,503 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,800 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,894 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:05,957 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,019 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,068 - father_agent.py - Step: 1530, Training loss: 0.49577903747558594
2024-09-03 01:51:06,162 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,289 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,358 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,468 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,532 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,595 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,659 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,693 - father_agent.py - Step: 1540, Training loss: 0.4966437816619873
2024-09-03 01:51:06,721 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,860 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:06,974 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,164 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,278 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,321 - father_agent.py - Step: 1550, Training loss: 0.3962383270263672
2024-09-03 01:51:07,363 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,540 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,649 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,718 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,798 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,882 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:07,941 - father_agent.py - Step: 1560, Training loss: 0.47016119956970215
2024-09-03 01:51:07,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,046 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,222 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,291 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,357 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,431 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,528 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,573 - father_agent.py - Step: 1570, Training loss: 0.523723840713501
2024-09-03 01:51:08,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,681 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:08,779 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,105 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,177 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,193 - father_agent.py - Step: 1580, Training loss: 0.47341349720954895
2024-09-03 01:51:09,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,389 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,473 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,593 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,695 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,786 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,815 - father_agent.py - Step: 1590, Training loss: 0.5263647437095642
2024-09-03 01:51:09,864 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,927 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:09,989 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,116 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,179 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,273 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,358 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,421 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,444 - father_agent.py - Step: 1600, Training loss: 0.4492585062980652
2024-09-03 01:51:10,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,787 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,859 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,890 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,921 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,952 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:10,996 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,026 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,065 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,169 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,199 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,229 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,272 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,302 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,333 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,419 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,448 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,522 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,553 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,609 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,648 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,690 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,719 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,753 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,784 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,815 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,845 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,881 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,924 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,954 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:11,984 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,019 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,055 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,093 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,159 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,190 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,222 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,224 - father_agent.py - Average Return = -26.825000762939453
2024-09-03 01:51:12,224 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:12,224 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:51:12,315 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,442 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,513 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,583 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,680 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,834 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:12,846 - father_agent.py - Step: 1610, Training loss: 0.45482534170150757
2024-09-03 01:51:12,926 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,080 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,144 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,243 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,318 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,381 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,444 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,476 - father_agent.py - Step: 1620, Training loss: 0.5136435031890869
2024-09-03 01:51:13,508 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,592 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,738 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,833 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:13,986 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,085 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,108 - father_agent.py - Step: 1630, Training loss: 0.5289607048034668
2024-09-03 01:51:14,149 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,218 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,381 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,446 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,730 - father_agent.py - Step: 1640, Training loss: 0.4115697145462036
2024-09-03 01:51:14,814 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,917 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:14,996 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,074 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,150 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,277 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,355 - father_agent.py - Step: 1650, Training loss: 0.4847100079059601
2024-09-03 01:51:15,393 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,507 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,577 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,640 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,709 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,834 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,926 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:15,982 - father_agent.py - Step: 1660, Training loss: 0.5879064798355103
2024-09-03 01:51:16,027 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,090 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,236 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,335 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,427 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,498 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,567 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,605 - father_agent.py - Step: 1670, Training loss: 0.48648789525032043
2024-09-03 01:51:16,670 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,747 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,810 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:16,901 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,000 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,072 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,186 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,224 - father_agent.py - Step: 1680, Training loss: 0.535117506980896
2024-09-03 01:51:17,268 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,331 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,414 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,477 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,549 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,614 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,684 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,831 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:17,852 - father_agent.py - Step: 1690, Training loss: 0.4697255492210388
2024-09-03 01:51:17,901 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,078 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,140 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,213 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,375 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,440 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,485 - father_agent.py - Step: 1700, Training loss: 0.4830552339553833
2024-09-03 01:51:18,772 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,808 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,844 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,876 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,912 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:18,966 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,008 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,051 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,127 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,175 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,205 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,294 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,325 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,361 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,399 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,428 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,459 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,493 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,559 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,620 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,664 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,694 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,731 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,766 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,797 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,827 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,897 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,962 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:19,993 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,026 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,074 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,108 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,152 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,238 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,269 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,329 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,362 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,400 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,402 - father_agent.py - Average Return = -30.075000762939453
2024-09-03 01:51:20,402 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:20,402 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:51:20,450 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,562 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,625 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,728 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,791 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,914 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:20,997 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,025 - father_agent.py - Step: 1710, Training loss: 0.6520817875862122
2024-09-03 01:51:21,090 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,182 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,246 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,368 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,450 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,514 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,654 - father_agent.py - Step: 1720, Training loss: 0.3850093185901642
2024-09-03 01:51:21,675 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,757 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,847 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:21,926 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,009 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,078 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,164 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,265 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,281 - father_agent.py - Step: 1730, Training loss: 0.5177434086799622
2024-09-03 01:51:22,350 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,413 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,492 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,569 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,664 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,735 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,855 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:22,909 - father_agent.py - Step: 1740, Training loss: 0.4462730288505554
2024-09-03 01:51:22,940 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,035 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,124 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,187 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,285 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,363 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,529 - father_agent.py - Step: 1750, Training loss: 0.5276945233345032
2024-09-03 01:51:23,570 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,640 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,851 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:23,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,038 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,116 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,150 - father_agent.py - Step: 1760, Training loss: 0.5541543364524841
2024-09-03 01:51:24,360 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,431 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,511 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,663 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,774 - father_agent.py - Step: 1770, Training loss: 0.4701899290084839
2024-09-03 01:51:24,812 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:24,913 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,028 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,093 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,191 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,316 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,428 - father_agent.py - Step: 1780, Training loss: 0.4417570233345032
2024-09-03 01:51:25,442 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,601 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,684 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,831 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:25,917 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,025 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,052 - father_agent.py - Step: 1790, Training loss: 0.47328394651412964
2024-09-03 01:51:26,086 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,147 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,216 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,316 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,386 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,460 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,621 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:26,678 - father_agent.py - Step: 1800, Training loss: 0.44931817054748535
2024-09-03 01:51:26,991 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,022 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,085 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,147 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,191 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,260 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,299 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,349 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,395 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,499 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,618 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,651 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,681 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,713 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,744 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,821 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,860 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,906 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,936 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:27,966 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,027 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,084 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,123 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,233 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,271 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,320 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,404 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,487 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,532 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,583 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,627 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,657 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,717 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,807 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,809 - father_agent.py - Average Return = -35.625
2024-09-03 01:51:28,809 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:28,809 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:51:28,887 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:28,959 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,030 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,094 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,157 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,221 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,379 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,439 - father_agent.py - Step: 1810, Training loss: 0.4719131886959076
2024-09-03 01:51:29,443 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,569 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,629 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,693 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,826 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:29,916 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,061 - father_agent.py - Step: 1820, Training loss: 0.47141334414482117
2024-09-03 01:51:30,088 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,164 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,298 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,380 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,460 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,524 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,603 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,686 - father_agent.py - Step: 1830, Training loss: 0.5311880707740784
2024-09-03 01:51:30,708 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,800 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:30,915 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,034 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,167 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,251 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,309 - father_agent.py - Step: 1840, Training loss: 0.5514378547668457
2024-09-03 01:51:31,356 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,440 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,509 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,646 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,760 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,824 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,888 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:31,934 - father_agent.py - Step: 1850, Training loss: 0.5023093819618225
2024-09-03 01:51:31,951 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,023 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,131 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,397 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,501 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,556 - father_agent.py - Step: 1860, Training loss: 0.4643523693084717
2024-09-03 01:51:32,580 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,657 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,720 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,790 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:32,881 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,144 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,174 - father_agent.py - Step: 1870, Training loss: 0.4402751922607422
2024-09-03 01:51:33,222 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,306 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,369 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,469 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,563 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,636 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,705 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,781 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,797 - father_agent.py - Step: 1880, Training loss: 0.4245426654815674
2024-09-03 01:51:33,865 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:33,992 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,063 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,150 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,214 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,386 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,428 - father_agent.py - Step: 1890, Training loss: 0.529595673084259
2024-09-03 01:51:34,472 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,535 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,688 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,777 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,840 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:34,903 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,013 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,053 - father_agent.py - Step: 1900, Training loss: 0.5595865845680237
2024-09-03 01:51:35,385 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,451 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,480 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,542 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,597 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,634 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,750 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,794 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,839 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,887 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:35,931 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,046 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,147 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,192 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,262 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,296 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,371 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,401 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,445 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,512 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,621 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,651 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,689 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,725 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,756 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,813 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,849 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,880 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,911 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,954 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:36,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,091 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,122 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,228 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,258 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,341 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,396 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,436 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,438 - father_agent.py - Average Return = -42.275001525878906
2024-09-03 01:51:37,438 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:37,438 - father_agent.py - Goal Reach Probability = 0.0
2024-09-03 01:51:37,507 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,570 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,640 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,828 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:37,922 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,013 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,062 - father_agent.py - Step: 1910, Training loss: 0.5351639986038208
2024-09-03 01:51:38,100 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,163 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,254 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,326 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,396 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,507 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,667 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,691 - father_agent.py - Step: 1920, Training loss: 0.4418049454689026
2024-09-03 01:51:38,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,829 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:38,899 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,021 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,134 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,212 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,274 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,316 - father_agent.py - Step: 1930, Training loss: 0.48015809059143066
2024-09-03 01:51:39,366 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,458 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,536 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,601 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,833 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,905 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:39,946 - father_agent.py - Step: 1940, Training loss: 0.41821202635765076
2024-09-03 01:51:39,994 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,145 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,208 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,303 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,420 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,569 - father_agent.py - Step: 1950, Training loss: 0.45326587557792664
2024-09-03 01:51:40,643 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,723 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,785 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,856 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,921 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:40,983 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,189 - father_agent.py - Step: 1960, Training loss: 0.4509890079498291
2024-09-03 01:51:41,220 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,283 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,347 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,412 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,475 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,538 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,598 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,779 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:41,814 - father_agent.py - Step: 1970, Training loss: 0.37079867720603943
2024-09-03 01:51:41,965 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,095 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,190 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,286 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,425 - father_agent.py - Step: 1980, Training loss: 0.47331857681274414
2024-09-03 01:51:42,457 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,520 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,596 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,686 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,819 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,880 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:42,942 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,005 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,044 - father_agent.py - Step: 1990, Training loss: 0.4997447729110718
2024-09-03 01:51:43,068 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,136 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,197 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,267 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,329 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,539 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:43,922 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,002 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,075 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,111 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,178 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,227 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,262 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,308 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,347 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,386 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,421 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,463 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,536 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,567 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,604 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,648 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,717 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,756 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,787 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,830 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,862 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,897 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:44,947 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,020 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,075 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,109 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,198 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,236 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,270 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,304 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,334 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,375 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,411 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,450 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,483 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,514 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,639 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,674 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,709 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,804 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,877 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,934 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:45,988 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,040 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,071 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,109 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,171 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,218 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,250 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,282 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,311 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,347 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,378 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,416 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,451 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,480 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,542 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,577 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,652 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,681 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,715 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,765 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,805 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,856 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,929 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:46,980 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,014 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,142 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,181 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,226 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,287 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,317 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,353 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,382 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,437 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,506 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,554 - environment_wrapper.py - Ended, but not in a goal state: []
2024-09-03 01:51:47,556 - father_agent.py - Average Return = -35.67499923706055
2024-09-03 01:51:47,556 - father_agent.py - Average Virtual Goal Value = -500.0
2024-09-03 01:51:47,556 - father_agent.py - Goal Reach Probability = 0.0

------------------------------------

PAYNT results: 
0.2436713977882082
controller size: 352

Storm results: 
0.2591092020812111
controller size: 1517

------------------------------------

